{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25765838-c700-4d5a-aa7a-aa33eb5498e5",
   "metadata": {},
   "source": [
    "Goal of this notebook is to finalize features and examples into arrays for train, train-val, val, and test sets with shuffled datasets, normalization, splitting datasets, and labels to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ef36a7-4ce2-4d92-a6f9-8ef802e8f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17914/3889554625.py:6: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries and Set Dependencies\n",
    "import importlib, os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display\n",
    "from icecream import ic\n",
    "\n",
    "sys.path.append('../')\n",
    "sys.path.append('/Volumes/Lab/Users/scooler/classification/')\n",
    "sys.path.append(\"/Volumes/Lab/Users/mads/artificial-retina-software-pipeline/artificial-retina-software-pipeline/utilities/\")\n",
    "sys.path.append(\"/Volumes/Lab/Users/mads/cell_class/moosa_share/\")\n",
    "\n",
    "import cell_display_lib as cdl\n",
    "import features as feat\n",
    "import features_visual as feat_v\n",
    "import features_electrical as feat_e\n",
    "import deduplication\n",
    "import features_DLelec as feat_dl\n",
    "\n",
    "import features\n",
    "import file_handling\n",
    "from scipy.signal import spectrogram \n",
    "import scipy.signal as signal\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "import visionloader as vl\n",
    "from conduction_velocity_code import get_axonal_conduction_velocity, upsample_ei, filter_ei_for_electrode_types\n",
    "from scipy import stats\n",
    "import eilib as el\n",
    "import math\n",
    "from skimage import measure\n",
    "from cell_display_lib import show\n",
    "import cv2\n",
    "import re\n",
    "\n",
    "import glob\n",
    "import resampy\n",
    "import random\n",
    "pd.set_option('display.max_rows', 4000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c8b1d0-3d54-47e6-b2aa-8b333dc76eaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load all possible datasets for train & train-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a36196e-02a3-432b-b5b5-122a665874cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train240to260.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train180to200.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train80to100.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train160to180.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train120to140.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train200to220.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train360to364.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train320to340.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train20to40.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train60to80.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train280to300.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train140to160.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train340to360.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train40to60.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train260to280.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train0to20.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train220to240.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train100to120.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/ctds_train300to320.pkl\n"
     ]
    }
   ],
   "source": [
    "# Looks for all the large dataset files, loads the piece information and concatenates to form dataset, cell, and unit tables\n",
    "import glob\n",
    "scratch_file_root = '/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/train/'\n",
    "ind = 0\n",
    "for file in glob.glob(scratch_file_root+ 'ctds_*'):\n",
    "    print(file)\n",
    "    \n",
    "    dt = pd.read_pickle(file)\n",
    "    if ind == 0:\n",
    "        dataset_tablet = dt\n",
    "    else:\n",
    "        dataset_tablet = pd.concat([dataset_tablet, dt],ignore_index = True)\n",
    "        # dataset_table.append(dt)\n",
    "        \n",
    "    pieces = np.array(dt.piece_id.unique())\n",
    "    for pp, piece_id in enumerate(pieces):\n",
    "        file_name = (scratch_file_root + 'ctd_' + piece_id)\n",
    "        # ds = pd.read_pickle(file_name + '_d.pkl')\n",
    "        cs = pd.read_pickle(file_name + '_c.pkl')\n",
    "        us = pd.read_pickle(file_name + '_u.pkl')\n",
    "        if pp == 0 and ind == 0:\n",
    "            ctt = cs\n",
    "            unit_tablet = us\n",
    "        else:\n",
    "            ctt = pd.concat([ctt, cs],ignore_index = True)\n",
    "            unit_tablet = pd.concat([unit_tablet, us],ignore_index = True)\n",
    "    ind += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "861d5031-8fa2-4489-937a-28406c197532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364 162051\n"
     ]
    }
   ],
   "source": [
    "# Check current number of datasets and cells\n",
    "print(len(dataset_tablet),len(unit_tablet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64299e51-f1cc-4d0f-a979-331b11a21123",
   "metadata": {},
   "source": [
    "## Load all possible datasets for test & test-val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d84c44-1bed-4dab-9e86-136e0af1c109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/ctds_test30to45.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/ctds_test45to52.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/ctds_test0to15.pkl\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/ctds_test15to30.pkl\n"
     ]
    }
   ],
   "source": [
    "# Looks for all the large dataset files, loads the piece information and concatenates to form dataset, cell, and unit tables\n",
    "import glob\n",
    "scratch_file_root = '/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/'\n",
    "ind = 0\n",
    "for file in glob.glob(scratch_file_root+ 'ctds_*'):\n",
    "    print(file)\n",
    "    \n",
    "    dt = pd.read_pickle(file)\n",
    "    if ind == 0:\n",
    "        dataset_table = dt\n",
    "    else:\n",
    "        dataset_table = pd.concat([dataset_table, dt],ignore_index = True)\n",
    "        # dataset_table.append(dt)\n",
    "        \n",
    "    pieces = np.array(dt.piece_id.unique())\n",
    "    for pp, piece_id in enumerate(pieces):\n",
    "        file_name = (scratch_file_root + 'ctd_' + piece_id)\n",
    "        # ds = pd.read_pickle(file_name + '_d.pkl')\n",
    "        cs = pd.read_pickle(file_name + '_c.pkl')\n",
    "        us = pd.read_pickle(file_name + '_u.pkl')\n",
    "        if pp == 0 and ind == 0:\n",
    "            ct = cs\n",
    "            unit_table = us\n",
    "        else:\n",
    "            ct = pd.concat([ct, cs],ignore_index = True)\n",
    "            unit_table = pd.concat([unit_table, us],ignore_index = True)\n",
    "    ind += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad179a6f-dedd-4f1a-9fa7-f84bd75291fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 31217\n"
     ]
    }
   ],
   "source": [
    "# Check current number of datasets and cells\n",
    "print(len(dataset_table),len(unit_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9f8f3-11d8-4d3c-8f73-4bdb128c4222",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "## Only Keep the 5 Major Cell Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13797946-6922-46b7-bcc0-7222918052bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep the 5 major cell types for our unit table of interest (easy to change)\n",
    "unit_tablet = unit_tablet.loc[unit_tablet['label_manual_text'].isin(['SBC','ON parasol','OFF parasol','ON midget','OFF midget'])]\n",
    "unit_table = unit_table.loc[unit_table['label_manual_text'].isin(['SBC','ON parasol','OFF parasol','ON midget','OFF midget'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d815da8-ff17-43d8-9f86-2cfb4e34293b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118949 20897\n"
     ]
    }
   ],
   "source": [
    "# Number of cells left\n",
    "print(len(unit_tablet),len(unit_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e55683f-fedd-4af3-9a6a-bdd46dfc93ec",
   "metadata": {},
   "source": [
    "## Lists for Which Datasets in train, training-validation, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99cd55ff-e385-4774-af89-6ea033c41b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which pieces will be used in training set, training-validation set, validation set, and test set\n",
    "pos_testvalsets = dataset_table['piece_id'].tolist()\n",
    "random.shuffle(pos_testvalsets)\n",
    "train_testvalsets = pos_testvalsets[:10]\n",
    "test_testvalsets = pos_testvalsets[10:31]\n",
    "val_testvalsets = pos_testvalsets[31:]\n",
    "\n",
    "pos_trainvalsets = dataset_tablet['piece_id'].tolist()\n",
    "pos_trainvalsets.append(train_testvalsets)\n",
    "random.shuffle(pos_trainvalsets)\n",
    "trainval_trainvalsets = pos_trainvalsets[:11]\n",
    "train_trainvalsets = pos_trainvalsets[11:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2199673-d1ee-4519-a87e-d760dd22bbe5",
   "metadata": {},
   "source": [
    "## Make Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e711b279-7dea-48f8-94da-dbe60e58d392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all units into one full dataset\n",
    "all_units = pd.concat([unit_table,unit_tablet],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e82b4d7-0be3-43b8-8ff1-f5111f5e231a",
   "metadata": {},
   "source": [
    "## Make Sure Dimensions are the Same for All Features of the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a7c25e-6895-417c-bd24-e222475d497f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acf\n",
      "Max Value:100\n",
      "Min Value:100\n",
      "New Max Value:100\n",
      "New Min Value:100\n",
      "spike_waveform_maxamplitude\n",
      "Max Value:181\n",
      "Min Value:51\n",
      "New Max Value:181\n",
      "New Min Value:181\n",
      "spec_spike_waveform\n",
      "Max Value:91\n",
      "Min Value:26\n",
      "New Max Value:91\n",
      "New Min Value:91\n",
      "spec_freq\n",
      "Max Value:91\n",
      "Min Value:26\n",
      "New Max Value:91\n",
      "New Min Value:91\n",
      "spec_acf\n",
      "Max Value:51\n",
      "Min Value:51\n",
      "New Max Value:51\n",
      "New Min Value:51\n",
      "spec_freq_acf\n",
      "Max Value:51\n",
      "Min Value:51\n",
      "New Max Value:51\n",
      "New Min Value:51\n"
     ]
    }
   ],
   "source": [
    "# For any undersampled time series, interpolate to fill them in\n",
    "# Features to Check Sizing: acf, spike waveform max amplitude, spec spike waveform, spec freq waveform, spec acf, \n",
    "# spec freq acf\n",
    "# Loop threw values to check\n",
    "check = ['acf', 'spike_waveform_maxamplitude', 'spec_spike_waveform', 'spec_freq', 'spec_acf', 'spec_freq_acf']\n",
    "\n",
    "for ind in check:\n",
    "    # Find max value\n",
    "    isolate = pd.Series(all_units[ind])\n",
    "    maxval = max(isolate.apply(lambda x: len(x.a.flatten())))\n",
    "    # argmaxval = np.argmax(isolate.apply(lambda x: len(x.a)))\n",
    "    print(ind)\n",
    "    print('Max Value:' + str(maxval))\n",
    "    minval = min(isolate.apply(lambda x: len(x.a.flatten())))\n",
    "    # argminval = np.argmin(isolate.apply(lambda x: len(x.a)))\n",
    "    print('Min Value:' + str(minval))\n",
    "    \n",
    "    for index, row in all_units.iterrows():\n",
    "        if len(all_units[ind][index].a.flatten()) < maxval:\n",
    "            FS = len(all_units[ind].iloc[index].a.flatten()) # samples per ms\n",
    "            all_units[ind].iloc[index].a = resampy.resample(all_units[ind].iloc[index].a.flatten(),FS,maxval)\n",
    "            # unit_tablet[ind][index].a = resampy.resample(unit_tablet[ind][index].a,FS,maxval)\n",
    "        elif len(all_units[ind][index].a.flatten()) > maxval:\n",
    "            print('max calc fail')\n",
    "    maxval = max(isolate.apply(lambda x: len(x.a.flatten())))\n",
    "    print('New Max Value:' + str(maxval))\n",
    "    minval = min(isolate.apply(lambda x: len(x.a.flatten())))\n",
    "    print('New Min Value:' + str(minval))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531bc897-ab91-4ff9-9213-c9481eaa68a0",
   "metadata": {},
   "source": [
    "## Split between Training/Training-Validation Set and Validation/Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2df89c58-34af-47f9-b3a7-6793829d4efd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/Lab/Development/miniconda-peggyo/envs/mads3/lib/python3.9/site-packages/numpy/core/fromnumeric.py:1822: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asanyarray(a).ravel(order=order)\n"
     ]
    }
   ],
   "source": [
    "trainingvalsets = np.append(trainval_trainvalsets, train_trainvalsets)\n",
    "valtestsets = np.append(val_testvalsets, test_testvalsets)\n",
    "trainingval = all_units.loc[all_units['piece_id'].isin(trainingvalsets)]\n",
    "valtesting = all_units.loc[all_units['piece_id'].isin(valtestsets)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ceda58-ceb3-41f8-bcd6-3691dea09e6d",
   "metadata": {},
   "source": [
    "## Normalize Training/Training Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83d299fa-a48d-4f58-980c-347bb3a54502",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17914/959375583.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trainingval[ind] = trainingval[ind].replace(np.nan,0)\n",
      "/tmp/ipykernel_17914/959375583.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trainingval[ind] = trainingval[ind].apply(lambda x: (x-mean)/std)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int_piece_id 205912696.03541854 93464139.67412134\n",
      "int_run_id 5.214562543611128 10.334919221980384\n",
      "spike_duration 1961.46574445268 1416.0678369435211\n",
      "spike_rate_mean 8.643154161811479 6.843364116284916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17914/959375583.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trainingval[ind] = trainingval[ind].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
      "/tmp/ipykernel_17914/959375583.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trainingval[ind] = trainingval[ind].replace(np.nan,0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retinal_eccentricity 9.95070576465544 13.811397667466162\n",
      "total_energy_ptnorm -0.47322464079653936 1.0863931287531015\n",
      "early_area 84.64295202145458 74.59593236969235\n",
      "early_peri 52.29307268544461 34.68428587409382\n",
      "early_circularity 0.34175932898028405 0.1981994493874022\n",
      "soma_area 2.580320137201658 1.2067695909704383\n",
      "soma_peri 7.089723772095203 1.9039958909934622\n",
      "soma_circularity 0.6038399547437479 0.16647480823182012\n",
      "spike_min_h 192.96990268421592 142.97555311422082\n",
      "spike_max_l 111.1448158887165 100.51678638132209\n",
      "spike_minmax_ratio 0.5654952647109163 4.888400184758875\n",
      "spike_width_half_min_amp 46.06658315748766 14.469028936919868\n",
      "spike_width_half_max_amp 101.65943387502207 39.793716380281836\n",
      "spike_area_amp_upper 3733.055642655824 2950.3985405894455\n",
      "spike_area_amp_lower 3228.250355711798 2556.567080090794\n",
      "spike_area_tr_amp_upper 3426.4879419093495 2675.0928609040147\n",
      "spike_area_tr_amp_lower 3115.481877481664 2426.956580595799\n",
      "spike_area2 8334.298099371097 7615.90861221812\n",
      "axon_vel 14.099974295867188 27.72741146521618\n"
     ]
    }
   ],
   "source": [
    "# Features to Normalize: pieceid, runid, spike duration, spike_rate_mean,retinal eccentricity, total energy,\n",
    "# early area, early peri,  early circularity, soma area, soma peri, \n",
    "# soma circularity, spike min h, spike max l, spike minmax ratio, spike width half min amp, \n",
    "# spike width half max amp, spike area amp upper, spike area amp lower, spike area tr amp upper, \n",
    "# spike area tr amp lower, spike slope amp upper, spike slopw amp lower, spike area2, axon vel\n",
    "norm = ['int_piece_id', 'int_run_id', 'spike_duration', 'spike_rate_mean', 'retinal_eccentricity',\n",
    "        'total_energy_ptnorm', 'early_area', 'early_peri', 'early_circularity',\n",
    "        'soma_area', 'soma_peri', 'soma_circularity', 'spike_min_h', 'spike_max_l',\n",
    "        'spike_minmax_ratio', 'spike_width_half_min_amp', 'spike_width_half_max_amp', \n",
    "        'spike_area_amp_upper', 'spike_area_amp_lower', 'spike_area_tr_amp_upper', \n",
    "        'spike_area_tr_amp_lower', 'spike_area2', 'axon_vel']\n",
    "\n",
    "# Future fix, piece id for experiments with 10 or more pieces\n",
    "mean_orig = []\n",
    "std_orig = []\n",
    "for ind in norm:\n",
    "    trainingval[ind] = trainingval[ind].replace(np.nan,0)\n",
    "    if isinstance(trainingval[ind].iloc[0],str):\n",
    "        trainingval[ind] = trainingval[ind].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "        trainingval[ind] = trainingval[ind].replace(np.nan,0)\n",
    "    isolate = pd.to_numeric(pd.Series(trainingval[ind]))\n",
    "    mean = isolate.mean()\n",
    "    mean_orig.append(mean)\n",
    "    std = isolate.std()\n",
    "    std_orig.append(std)\n",
    "    print(ind, mean, std)\n",
    "    trainingval[ind] = trainingval[ind].apply(lambda x: (x-mean)/std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71358eb-0f15-4ba9-b5bc-eae0945602ca",
   "metadata": {},
   "source": [
    "## Normalize Validation/Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59c1fbaf-c6e3-462b-834c-295f7e648b11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17914/2615685640.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valtesting[ind] = valtesting[ind].replace(np.nan,0)\n",
      "/tmp/ipykernel_17914/2615685640.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valtesting[ind] = valtesting[ind].apply(lambda x: (x-mean_orig[index])/std_orig[index])\n",
      "/tmp/ipykernel_17914/2615685640.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valtesting[ind] = valtesting[ind].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
      "/tmp/ipykernel_17914/2615685640.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  valtesting[ind] = valtesting[ind].replace(np.nan,0)\n"
     ]
    }
   ],
   "source": [
    "norm = ['int_piece_id', 'int_run_id', 'spike_duration', 'spike_rate_mean', 'retinal_eccentricity',\n",
    "        'total_energy_ptnorm', 'early_area', 'early_peri', 'early_circularity',\n",
    "        'soma_area', 'soma_peri', 'soma_circularity', 'spike_min_h', 'spike_max_l',\n",
    "        'spike_minmax_ratio', 'spike_width_half_min_amp', 'spike_width_half_max_amp', \n",
    "        'spike_area_amp_upper', 'spike_area_amp_lower', 'spike_area_tr_amp_upper', \n",
    "        'spike_area_tr_amp_lower', 'spike_area2', 'axon_vel']\n",
    "\n",
    "# Future fix, piece id for experiments with 10 or more pieces\n",
    "index = 0\n",
    "for ind in norm:\n",
    "    valtesting[ind] = valtesting[ind].replace(np.nan,0)\n",
    "    if isinstance(valtesting[ind].iloc[0],str):\n",
    "        valtesting[ind] = valtesting[ind].apply(lambda x: pd.to_numeric(x, errors='coerce'))\n",
    "        valtesting[ind] = valtesting[ind].replace(np.nan,0)\n",
    "    \n",
    "    valtesting[ind] = valtesting[ind].apply(lambda x: (x-mean_orig[index])/std_orig[index])\n",
    "    index += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24289722-fbb4-43cb-b53a-ede378e56e27",
   "metadata": {},
   "source": [
    "## Make Example & Label Arrays for Each Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c357de2-4858-4834-94a6-1cc1b4fbf719",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acf\n",
      "test done\n",
      "val done\n",
      "train val done\n",
      "train done\n",
      "spike_waveform_maxamplitude\n",
      "test done\n",
      "val done\n",
      "train val done\n",
      "train done\n",
      "spec_spike_waveform\n",
      "test done\n",
      "val done\n",
      "train val done\n",
      "train done\n",
      "spec_freq\n",
      "test done\n",
      "val done\n",
      "train val done\n",
      "train done\n",
      "spec_acf\n",
      "test done\n",
      "val done\n",
      "train val done\n",
      "train done\n",
      "spec_freq_acf\n",
      "test done\n",
      "val done\n",
      "train val done\n",
      "train done\n",
      "early_centroid\n",
      "test done\n",
      "val done\n",
      "train val done\n",
      "train done\n",
      "soma_centroid\n",
      "test done\n",
      "val done\n",
      "train val done\n",
      "train done\n"
     ]
    }
   ],
   "source": [
    "# Labels Here:\n",
    "testpos_labels = valtesting['label_manual_text'][valtesting['piece_id'].isin(test_testvalsets)].tolist()\n",
    "valpos_labels = valtesting['label_manual_text'][valtesting['piece_id'].isin(val_testvalsets)].tolist()\n",
    "trainval_labels = trainingval['label_manual_text'][trainingval['piece_id'].isin(trainval_trainvalsets)].tolist()\n",
    "train_labels = trainingval['label_manual_text'][trainingval['piece_id'].isin(train_trainvalsets)].tolist()\n",
    "\n",
    "# Single Number Features for Examples Here:\n",
    "singfeat = ['spike_duration','spike_rate_mean','int_piece_id', 'int_run_id','retinal_eccentricity',\n",
    "        'total_energy_ptnorm', 'early_area', 'early_peri', 'early_circularity',\n",
    "        'soma_area', 'soma_peri', 'soma_circularity', 'spike_min_h', 'spike_max_l',\n",
    "        'spike_minmax_ratio', 'spike_width_half_min_amp', 'spike_width_half_max_amp', \n",
    "        'spike_area_amp_upper', 'spike_area_amp_lower', 'spike_area_tr_amp_upper', \n",
    "        'spike_area_tr_amp_lower', 'spike_area2', 'axon_vel']\n",
    "\n",
    "arrfeat = ['acf', 'spike_waveform_maxamplitude', 'spec_spike_waveform', 'spec_freq', 'spec_acf', \n",
    "           'spec_freq_acf', 'early_centroid','soma_centroid']\n",
    "\n",
    "test_feat = valtesting[singfeat][valtesting['piece_id'].isin(test_testvalsets)].to_numpy()\n",
    "val_feat = valtesting[singfeat][valtesting['piece_id'].isin(val_testvalsets)].to_numpy()\n",
    "trainval_feat = trainingval[singfeat][trainingval['piece_id'].isin(trainval_trainvalsets)].to_numpy()\n",
    "train_feat = trainingval[singfeat][trainingval['piece_id'].isin(train_trainvalsets)].to_numpy()\n",
    "\n",
    "# Time Series Features Here:\n",
    "\n",
    "for ind in arrfeat:\n",
    "    print(ind)\n",
    "    if ind == 'early_centroid' or ind == 'soma_centroid':\n",
    "        isolate1 = pd.Series(valtesting[ind]).apply(lambda x: np.asarray(x))\n",
    "        isolate2 = pd.Series(trainingval[ind]).apply(lambda x: np.asarray(x))\n",
    "        \n",
    "        seriesA = isolate1[valtesting['piece_id'].isin(test_testvalsets)].apply(lambda x: np.asarray(x.a))\n",
    "        array = seriesA.to_numpy()\n",
    "        final = np.vstack(array)\n",
    "        test_feat = np.concatenate((test_feat, final),axis=1)\n",
    "        print('test done')\n",
    "        \n",
    "        seriesA = isolate1[valtesting['piece_id'].isin(val_testvalsets)].apply(lambda x: np.asarray(x.a))\n",
    "        array = seriesA.to_numpy()\n",
    "        final = np.vstack(array)\n",
    "        val_feat = np.concatenate((val_feat, final),axis=1)\n",
    "        print('val done')\n",
    "\n",
    "        seriesA = isolate2[trainingval['piece_id'].isin(trainval_trainvalsets)].apply(lambda x: np.asarray(x.a))\n",
    "        array = seriesA.to_numpy()\n",
    "        final = np.vstack(array)\n",
    "        trainval_feat = np.concatenate((trainval_feat, final),axis=1)\n",
    "        print('train val done')\n",
    "\n",
    "        seriesA = isolate2[trainingval['piece_id'].isin(train_trainvalsets)].apply(lambda x: np.asarray(x.a))\n",
    "        array = seriesA.to_numpy()\n",
    "        final = np.vstack(array)\n",
    "        train_feat = np.concatenate((train_feat, final),axis=1)\n",
    "        print('train done')\n",
    "        \n",
    "    else:\n",
    "        isolate1 = pd.Series(valtesting[ind]).apply(lambda x: x.a.flatten())\n",
    "        isolate2 = pd.Series(trainingval[ind]).apply(lambda x: x.a.flatten())\n",
    "    \n",
    "        seriesA = isolate1[valtesting['piece_id'].isin(test_testvalsets)].apply(lambda x: x)\n",
    "        array = seriesA.to_numpy()\n",
    "        final = np.vstack(array)\n",
    "        test_feat = np.concatenate((test_feat, final),axis=1)\n",
    "        print('test done')\n",
    "\n",
    "        seriesA = isolate1[valtesting['piece_id'].isin(val_testvalsets)].apply(lambda x: x)\n",
    "        array = seriesA.to_numpy()\n",
    "        final = np.vstack(array)\n",
    "        val_feat = np.concatenate((val_feat, final),axis=1)\n",
    "        print('val done')\n",
    "\n",
    "        seriesA = isolate2[trainingval['piece_id'].isin(trainval_trainvalsets)].apply(lambda x: x)\n",
    "        array = seriesA.to_numpy()\n",
    "        final = np.vstack(array)\n",
    "        trainval_feat = np.concatenate((trainval_feat, final),axis=1)\n",
    "        print('train val done')\n",
    "\n",
    "        seriesA = isolate2[trainingval['piece_id'].isin(train_trainvalsets)].apply(lambda x: x)\n",
    "        array = seriesA.to_numpy()\n",
    "        final = np.vstack(array)\n",
    "        train_feat = np.concatenate((train_feat, final),axis=1)\n",
    "        print('train done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81c9b152-786e-4b70-8c02-90bd389f5278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 16]\n"
     ]
    }
   ],
   "source": [
    "isolate1 = pd.Series(valtesting['early_centroid']).apply(lambda x: np.asarray(x))\n",
    "isolate1 = isolate1.apply(lambda x: np.asarray(x.a))\n",
    "print(isolate1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b9f9f30f-3620-4d34-ab19-79a02418d6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 26]\n",
      "['__add__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__delitem__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__iadd__', '__imul__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__reversed__', '__rmul__', '__setattr__', '__setitem__', '__sizeof__', '__str__', '__subclasshook__', 'append', 'clear', 'copy', 'count', 'extend', 'index', 'insert', 'pop', 'remove', 'reverse', 'sort']\n",
      "[<file_handling.wrapper object at 0x7f9bec2fc2b0>, <file_handling.wrapper object at 0x7f9bec2fc310>, <file_handling.wrapper object at 0x7f9bec2fc370>, <file_handling.wrapper object at 0x7f9bec2fc3d0>, <file_handling.wrapper object at 0x7f9bec2fc430>, <file_handling.wrapper object at 0x7f9bec2fc490>, <file_handling.wrapper object at 0x7f9bec2fc4f0>, <file_handling.wrapper object at 0x7f9bec2fc550>, <file_handling.wrapper object at 0x7f9bec2fc610>, <file_handling.wrapper object at 0x7f9bec2fc670>]\n"
     ]
    }
   ],
   "source": [
    "isolate2 = pd.Series(trainingval['early_centroid'])\n",
    "print(isolate2.iloc[5000].a)\n",
    "\n",
    "test = isolate2.to_list()\n",
    "print(dir(test))\n",
    "print(test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3424cd98-451a-4c67-9c65-74a7168e5ece",
   "metadata": {},
   "source": [
    "## Check Features are All Good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4abe93e-541d-4730-a521-354f750b1891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115163, 590)\n",
      "(3786, 592)\n",
      "(7980, 592)\n",
      "(8577, 592)\n",
      "unit_id                                        1.0\n",
      "dataset_id                     (2012-09-27-3, 003)\n",
      "run_id                                         003\n",
      "piece_id                              2012-09-27-3\n",
      "valid                                         True\n",
      "label_manual_text_input                OFF parasol\n",
      "spike_duration                           -0.000372\n",
      "spike_rate_mean                           2.806329\n",
      "acf                                           a100\n",
      "spike_waveform_maxamplitude                   a181\n",
      "int_piece_id                             -0.050323\n",
      "int_run_id                                -0.21428\n",
      "spec_spike_waveform                            a91\n",
      "spec_freq                                      a91\n",
      "spec_timeoverlap                                a1\n",
      "spec_acf                                     a51x1\n",
      "spec_freq_acf                                  a51\n",
      "spec_timeoverlap_acf                        0.0025\n",
      "retinal_eccentricity                      0.075973\n",
      "total_energy_ptnorm                       0.143554\n",
      "early_area                                 0.64155\n",
      "early_peri                                1.016693\n",
      "early_centroid                            [17, 16]\n",
      "early_circularity                        -0.628478\n",
      "soma_area                                  1.17643\n",
      "soma_peri                                 0.913186\n",
      "soma_centroid                             [45, 12]\n",
      "soma_circularity                          0.246741\n",
      "spike_min_h                               1.724581\n",
      "spike_max_l                               1.291238\n",
      "spike_minmax_ratio                       -0.003548\n",
      "spike_width_half_min_amp                 -0.073715\n",
      "spike_area_amp_upper                      1.661393\n",
      "spike_area_amp_lower                      1.529893\n",
      "spike_area_tr_amp_upper                   1.676683\n",
      "spike_area_tr_amp_lower                   1.568762\n",
      "spike_slope_amp_upper                    18.314285\n",
      "spike_slope_amp_lower                    20.930612\n",
      "spike_area2                               1.122602\n",
      "spike_width_half_max_amp                 -0.318126\n",
      "axon_vel                                   2.29983\n",
      "label_manual_input                            38.0\n",
      "cell_id                          (2012-09-27-3, 0)\n",
      "label_manual_text                      OFF parasol\n",
      "label_manual                                  38.0\n",
      "Name: 0, dtype: object\n",
      "[-0.11409654272030746 -1.0926690402528274 -0.0492445022386797\n",
      " -0.504557648841682 -0.1412388385029621 1.1691465428340257\n",
      " -1.127983113133406 -1.4092508441634966 0.9952235675936972\n",
      " -0.8952165726457405 -0.8799967698728062 0.2354035018173922\n",
      " -0.31270663874699833 -0.8201410522210202 -0.07607206746406206\n",
      " 0.13362450589748545 -0.09196009339895075 -0.20770696891881332\n",
      " -0.2548277522244443 -0.20014566141616197 -0.2757295557153919\n",
      " -0.7989548781993814 -0.5085211186610584 0.00016144473447755954\n",
      " 0.0002812183014397432 0.00012246254627097493 0.0 0.00037157174032839707\n",
      " 8.090444542547539e-05 7.046315507006839e-05 6.136938701349845e-05\n",
      " 0.00010689846796293664 0.0 8.108693430956766e-05 3.531104623709813e-05\n",
      " 3.0753906211283824e-05 8.035469192006783e-05 0.00018662493637095688\n",
      " 4.063491740871495e-05 0.00015925812385306033 9.246982509807993e-05\n",
      " 5.3690627183068646e-05 8.18325766396305e-05 7.127150439283323e-05\n",
      " 6.20734131443411e-05 8.495520088857211e-05 3.3632332689950925e-05\n",
      " 7.030042202216773e-05 6.122765581530628e-05 8.887632365979884e-05\n",
      " 9.675775761090107e-05 0.00010786622118141811 6.752320101548975e-05\n",
      " 7.415029518698105e-05 7.348835504417452e-05 6.206464344707083e-05\n",
      " 5.405476265958525e-05 5.590585363311893e-05 6.278551582306741e-05\n",
      " 3.6827058059956404e-05 4.3737635449387335e-05 5.9255753733855936e-05\n",
      " 4.276122915243546e-05 6.677981722984055e-05 4.529879044036857e-05\n",
      " 4.188801092373046e-05 3.945153771259376e-05 3.6207351876266684e-05\n",
      " 3.2821661244778344e-05 2.8025288178717787e-05 2.5140679513075412e-05\n",
      " 2.104576330615771e-05 1.5552437804909323e-05 1.1932751786930787e-05\n",
      " 1.2218498501256512e-05 9.173805977060947e-06 5.433105815465648e-06\n",
      " 4.824707964970511e-06 2.5050654736025813e-06 2.463287663477819e-06\n",
      " 1.164636477485172e-06 9.609460206719303e-07 4.649606370170487e-07\n",
      " 6.074312720761773e-07 4.937687760012663e-07 2.7645713130423205e-07\n",
      " 1.605189233700019e-07 1.3980282207755107e-07 8.117352002499246e-08\n",
      " 1.767437592280733e-08 3.078674564459176e-08 5.3626997158170026e-08\n",
      " 1.167651356123236e-08 0.0 8.857121211809105e-09 0.0 6.718494844312024e-09\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n",
      " 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.8410279750823975 0.8544922471046448\n",
      " 0.6103229522705078 0.3068746328353882 0.05994207039475441\n",
      " -0.1692005693912506 -0.4525139629840851 -0.7864438891410828\n",
      " -1.1241257190704346 -1.450799584388733 -1.773229718208313\n",
      " -2.063814401626587 -2.276599645614624 -2.420987606048584\n",
      " -2.569150924682617 -2.7719085216522217 -3.0055439472198486\n",
      " -3.2245864868164062 -3.4267284870147705 -3.6233391761779785\n",
      " -3.7775795459747314 -3.8384451866149902 -3.8335442543029785\n",
      " -3.8516383171081543 -3.897355079650879 -3.828458786010742\n",
      " -3.5059492588043213 -2.966464042663574 -2.355299234390259\n",
      " -1.704878568649292 -0.9125906229019165 -0.0062189348973333836\n",
      " 0.672019362449646 0.6502706408500671 -0.43732699751853943\n",
      " -3.1044797897338867 -8.608804702758789 -18.95597267150879\n",
      " -35.719181060791016 -58.436946868896484 -84.13282775878906\n",
      " -108.58771514892578 -128.29383850097656 -141.46849060058594\n",
      " -147.6775665283203 -147.04405212402344 -140.05751037597656\n",
      " -127.88070678710938 -112.33610534667969 -95.29027557373047\n",
      " -78.03540802001953 -61.27838134765625 -45.55963134765625\n",
      " -31.46309471130371 -19.400413513183594 -9.376352310180664\n",
      " -1.1131216287612915 5.63491153717041 10.987532615661621\n",
      " 15.120360374450684 18.38338279724121 21.141841888427734 23.5413818359375\n",
      " 25.503456115722656 26.93699073791504 27.88558006286621 28.46126937866211\n",
      " 28.710880279541016 28.606029510498047 28.136404037475586\n",
      " 27.356271743774414 26.341482162475586 25.15277671813965\n",
      " 23.860538482666016 22.562862396240234 21.333629608154297\n",
      " 20.159931182861328 18.964956283569336 17.699905395507812\n",
      " 16.392379760742188 15.103263854980469 13.866711616516113\n",
      " 12.69218635559082 11.601777076721191 10.63062858581543 9.793994903564453\n",
      " 9.087529182434082 8.528454780578613 8.158982276916504 7.9739274978637695\n",
      " 7.862947463989258 7.676884174346924 7.374068737030029 7.071263790130615\n",
      " 6.914674758911133 6.910295486450195 6.921350479125977 6.844818115234375\n",
      " 6.753791332244873 6.826174259185791 7.140637397766113 7.584343433380127\n",
      " 7.978529930114746 8.262020111083984 8.512215614318848 8.796979904174805\n",
      " 9.061352729797363 9.195293426513672 9.186213493347168 9.151074409484863\n",
      " 9.204288482666016 9.333420753479004 9.441417694091797 9.492778778076172\n",
      " 9.565546035766602 9.738625526428223 9.964136123657227 10.096531867980957\n",
      " 10.047015190124512 9.872208595275879 9.693739891052246 9.559005737304688\n",
      " 9.414655685424805 9.208412170410156 8.976466178894043 8.810022354125977\n",
      " 8.754914283752441 8.767670631408691 8.762398719787598 8.676647186279297\n",
      " 8.491815567016602 8.219319343566895 7.889786720275879 7.546270847320557\n",
      " 7.225582122802734 6.940979480743408 6.690868854522705 6.479789733886719\n",
      " 6.314505100250244 6.179211616516113 6.038860321044922 5.883962631225586\n",
      " 5.75532865524292 5.695163726806641 5.673033714294434 5.589962005615234\n",
      " 5.376246452331543 5.074008464813232 4.805237293243408 4.662256240844727\n",
      " 4.6415839195251465 4.674871921539307 4.6996541023254395 4.699335098266602\n",
      " 4.7041778564453125 4.770671367645264 4.936856269836426 5.170434474945068\n",
      " 5.375364303588867 5.48564338684082 5.548448085784912 5.668517589569092\n",
      " 5.8552751541137695 5.978095531463623 5.92334508895874 5.759742259979248\n",
      " 5.6656174659729 5.687319755554199 5.666735649108887 5.4732770919799805\n",
      " 5.229693412780762 5.1766510009765625 5.316359519958496 5.3444037437438965\n",
      " 5.035625457763672 4.589820384979248 4.403367519378662 4.479071140289307\n",
      " 4.258193492889404 3.2097887992858887 1.5313796997070312\n",
      " 0.05115567147731781 0.34070730209350586 0.6158570051193237\n",
      " 0.7086188793182373 0.6317393183708191 0.5471625924110413\n",
      " 0.5727915167808533 0.661828875541687 0.6844020485877991\n",
      " 0.5890137553215027 0.44508975744247437 0.34111735224723816\n",
      " 0.28853094577789307 0.24234788119792938 0.1815478354692459\n",
      " 0.13138620555400848 0.11357583105564117 0.11058136075735092\n",
      " 0.0934121385216713 0.06330491602420807 0.04483543336391449\n",
      " 0.04638411104679108 0.049035508185625076 0.0365259051322937\n",
      " 0.018080152571201324 0.011905830353498459 0.01774350367486477\n",
      " 0.019414514303207397 0.01011514663696289 0.001020719762891531\n",
      " 0.0025645142886787653 0.008878174237906933 0.007965615019202232\n",
      " 8.407693712797482e-06 -0.004010125529021025 0.0005166608607396483\n",
      " 0.005591090302914381 0.003429919481277466 -0.002292030956596136\n",
      " -0.0030499601271003485 0.0015503603499382734 0.004049168433994055\n",
      " 0.0008754346636123955 -0.002833510050550103 -0.0016734939999878407\n",
      " 0.002077704295516014 0.0026018323842436075 -0.0005656481953337789\n",
      " -0.0024247602559626102 -0.00041836846503429115 0.0020811257418245077\n",
      " 0.0013442534254863858 -0.001217514625750482 -0.0016736517427489161\n",
      " 0.00040146990795619786 0.0016903470968827605 0.00039353271131403744\n",
      " -0.0013120642397552729 -0.0008979719132184982 0.0007881830679252744\n",
      " 0.0011462111724540591 -0.0001860207412391901 -0.0010696790413931012\n",
      " -0.0002755927562247962 0.0008365661487914622 0.0006092407857067883\n",
      " -0.0004663316940423101 -0.0007271153153851628 0.00010230804036837071\n",
      " 0.0006838818662799895 0.0002091990754706785 -0.0004985303385183215\n",
      " -0.0003877170092891902 0.0002718734904192388 0.00045567104825749993\n",
      " -3.459870276856236e-05 -0.0003983342903666198 -0.0001293431269004941\n",
      " 0.0002952110371552408 0.00024099885195028037 -0.00014706388174090534\n",
      " -0.0002643957268446684 1.7682925317785703e-05 0.00023635316756553948\n",
      " 8.82442036527209e-05 -0.00015999107563402504 -0.00013963204401079565\n",
      " 7.769146759528667e-05 0.0001511242298875004 -8.572826004638046e-07\n",
      " -0.00012606351810973138 2.634564869370565 86.94943365533886\n",
      " 214.4057292190529 344.8789452156184 454.08522490973405 551.3447255061645\n",
      " 658.4958514761562 779.4022569966131 898.1267640215037 1003.8508130132294\n",
      " 1105.8479766963032 1218.4344907556704 1339.3105590906375\n",
      " 1453.3969402064504 1556.082928399837 1660.6057174341283\n",
      " 1777.8231448543036 1898.88260410539 2008.1882459695987 2107.962997364728\n",
      " 2216.050569730425 2338.373061435594 2458.2280856181414 2561.2767216505963\n",
      " 2659.165490526485 2773.234203778488 2900.660886699413 3016.404148456038\n",
      " 3111.731676795932 3210.4087030045985 3333.476486110435 3464.403230928043\n",
      " 3571.798556216572 3659.186395312512 3763.3570611890786 3897.925506447333\n",
      " 4028.236078520949 4122.506901977875 4204.310129184434 4320.447940230101\n",
      " 4466.946005989414 4589.60698187733 4666.949297285154 4749.213597030295\n",
      " 4884.411678270346 5039.463302840784 5144.991884387427 5204.671813848158\n",
      " 5297.578065752789 5457.475719093588 5612.465837348542 5690.515541628001\n",
      " 5737.153579630549 5854.36993197633 6040.3877208608355 6180.856654795391\n",
      " 6222.896469437209 6268.393615412094 6425.143688307417 6631.495754078953\n",
      " 6737.726596446082 6740.487330870858 6805.1369822802235 7015.153328017057\n",
      " 7226.114938142584 7274.844258300193 7244.0553952794 7356.872903548842\n",
      " 7628.8023917892615 7816.212344280819 7782.63344063577 7736.891382966534\n",
      " 7936.483963834342 8270.577746404892 8389.757096994974 8247.35677960532\n",
      " 8223.70951287923 8565.019186795642 8951.074476558362 8926.300075918612\n",
      " 8635.793146475275 8706.853340246698 9299.567976871827 9718.867224519714\n",
      " 9363.796329152201 8789.891888280157 9168.700696130081 10515.270981453188\n",
      " 11039.705068129873 8886.528257901216 4429.9790494899\n",
      " 3.676292064219232e-13 3.198713034254829e-12 7.330831126743739e-13\n",
      " 3.616248626833898e-14 9.216566760438402e-15 3.870397771428491e-15\n",
      " 2.13411689529411e-14 4.134223086176881e-14 4.45673083883875e-14\n",
      " 2.677814711294124e-14 5.7972234828858395e-15 4.661701175670215e-17\n",
      " 2.715646664692373e-16 2.0275397294902788e-16 3.746592268553839e-15\n",
      " 1.2722356634519208e-14 1.8202199866685267e-14 1.1869433720469447e-14\n",
      " 2.2801458647541457e-15 1.4921736250985772e-16 3.174772305148151e-16\n",
      " 5.194208658329953e-16 2.3673727521998293e-15 4.059316617212615e-15\n",
      " 2.19964573457358e-15 1.0656641698453968e-15 1.4852377267310007e-15\n",
      " 1.852159357430241e-15 4.6150224054660205e-15 1.0212780075311848e-14\n",
      " 8.233805017205932e-15 6.073549595402894e-16 5.651264217038919e-15\n",
      " 1.7211844196760656e-14 1.6816500994101223e-14 5.268378399398176e-15\n",
      " 5.4993349644270875e-15 1.846060872355264e-14 2.117338772328819e-14\n",
      " 8.774686004612028e-15 8.273436180894503e-17 5.5423302977555545e-15\n",
      " 1.3669169136412772e-14 1.1839727902641632e-14 4.761301158781329e-15\n",
      " 1.044774081104976e-15 1.584667716817562e-15 1.8560554814178233e-15\n",
      " 4.796551500079989e-15 2.055975465200399e-14 1.7006262264225902e-14 0.0\n",
      " 200.0 400.0 600.0 800.0 1000.0 1200.0 1400.0 1600.0 1800.0 2000.0 2200.0\n",
      " 2400.0 2600.0 2800.0 3000.0 3200.0 3400.0 3600.0 3800.0 4000.0 4200.0\n",
      " 4400.0 4600.0 4800.0 5000.0 5200.0 5400.0 5600.0 5800.0 6000.0 6200.0\n",
      " 6400.0 6600.0 6800.0 7000.0 7200.0 7400.0 7600.0 7800.0 8000.0 8200.0\n",
      " 8400.0 8600.0 8800.0 9000.0 9200.0 9400.0 9600.0 9800.0 10000.0\n",
      " <file_handling.wrapper object at 0x7f9bec2fc2b0>\n",
      " <file_handling.wrapper object at 0x7f9bec29d310>]\n"
     ]
    }
   ],
   "source": [
    "print(train_feat.shape)\n",
    "print(trainval_feat.shape)\n",
    "print(test_feat.shape)\n",
    "print(val_feat.shape)\n",
    "print(valtesting.iloc[0])\n",
    "print(train_feat[0,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2888343f-363a-4db1-bbd1-7d1b40d45b1d",
   "metadata": {},
   "source": [
    "## Save arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ade88f-effc-4582-896c-7c9aae5b232e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
