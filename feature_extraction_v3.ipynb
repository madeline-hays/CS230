{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d007d02-c548-42e2-a191-774eaa214b67",
   "metadata": {},
   "source": [
    "Note to Self: Goal of this Notebook is to Generate Features for Val and Test Sets. Complete in Sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bbefeb-6384-465e-b9cb-ac26782ea4af",
   "metadata": {},
   "source": [
    "## Import Libraries and Set Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45500e5d-c56a-44bf-a08f-66cd5cbfd990",
   "metadata": {},
   "source": [
    "Terminology:\n",
    "-Dataset Table = dataframe containing retina pieces identified by date and section of retina and which recordings from those pieces we care about along with other pertinent analysis information (i.e. animal age, retinal eccentricity, etc.)\n",
    "-Cell Table = dataframe containing cells identified in retinal pieces\n",
    "-Unit Table = dataframe containing identified neurons (i.e. unit) where two units may relate to a single cell. Contains most of the information we care about EI, spike waveform, interspike interval\n",
    "-Electrical Image (EI) = when recording a single cell spike, what is the average signal we record across a large array over time. Many possible features can be calculated from the EI.\n",
    "-Spike Waveform = when recording a single cell spike, the average spike that occurs at the electrode that records the highest amplitudes of the EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d62e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18063/1875288024.py:5: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modules loaded! GO TIME\n"
     ]
    }
   ],
   "source": [
    "import importlib, os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display\n",
    "from icecream import ic\n",
    "\n",
    "# Paths for cell display library, visionloader, axon conduction velocity caluclations\n",
    "sys.path.append('../')\n",
    "sys.path.append('/Volumes/Lab/Users/scooler/classification/')\n",
    "sys.path.append(\"/Volumes/Lab/Users/mads/artificial-retina-software-pipeline/artificial-retina-software-pipeline/utilities/\")\n",
    "sys.path.append(\"/Volumes/Lab/Users/mads/cell_class/moosa_share/\")\n",
    "\n",
    "# Standard cell display library \n",
    "import cell_display_lib as cdl\n",
    "import features as feat\n",
    "import features_visual as feat_v\n",
    "import features_electrical as feat_e\n",
    "import deduplication\n",
    "import features_DLelec as feat_dl\n",
    "import features\n",
    "\n",
    "# Specific feature libraries\n",
    "import file_handling\n",
    "from scipy.signal import spectrogram \n",
    "import scipy.signal as signal\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "import visionloader as vl\n",
    "from conduction_velocity_code import get_axonal_conduction_velocity, upsample_ei, filter_ei_for_electrode_types\n",
    "from scipy import stats\n",
    "import eilib as el\n",
    "import math\n",
    "from skimage import measure\n",
    "from cell_display_lib import show\n",
    "import cv2\n",
    "import re\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print('modules loaded! GO TIME')\n",
    "\n",
    "# Your custom parameters\n",
    "load_file = False\n",
    "save_file = True\n",
    "save_name = 'featExtract_test'  # customize this!\n",
    "scratch_file_root = '/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL' # replace my name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1dca68-7ea1-49ce-97d4-174100addb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or you could skip down to here and just load\n",
    "load_file = 1\n",
    "if load_file:\n",
    "    importlib.reload(cdl)\n",
    "    ct = cdl.CellTable()\n",
    "    pieces = piece_run.keys()\n",
    "    ct.file_load_pieces(pieces=pieces, file_root=scratch_file_root, process_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dbeac1-077b-4bc4-b765-7a3192bbdd4b",
   "metadata": {},
   "source": [
    "## LOAD in Dataset Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aee48e2b-303d-4bba-9662-00e1b3647710",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           piece                                          path  run    sorter\n",
      "0   2005-04-06-0                          2005-04-06-0/data001  001    vision\n",
      "1   2005-04-06-4  2005-04-06-4/pipeline_classification/data000  000    vision\n",
      "2   2005-04-26-0  2005-04-26-0/pipeline_classification/data002  002    vision\n",
      "3   2005-07-26-4  2005-07-26-4/pipeline_classification/data001  001    vision\n",
      "4   2006-05-04-0                          2006-05-04-0/data000  000    vision\n",
      "5   2006-05-04-2    2006-05-04-2/CT_EI_Analysis_Gorish/data005  005    vision\n",
      "6   2006-07-14-1  2006-07-14-1/pipeline_classification/data012  012    vision\n",
      "7   2006-11-01-2                          2006-11-01-2/data000  000    vision\n",
      "8   2006-11-01-4                          2006-11-01-4/data000  000    vision\n",
      "9   2007-02-06-1         2007-02-06-1/kilosort_data015/data015  015  kilosort\n",
      "10  2007-02-06-4         2007-02-06-4/kilosort_data015/data015  015  kilosort\n",
      "11  2007-02-06-6  2007-02-06-6/pipeline_classification/data007  007    vision\n",
      "12  2007-03-02-0  2007-03-02-0/pipeline_classification/data015  015    vision\n",
      "13  2007-03-02-3  2007-03-02-3/pipeline_classification/data010  010    vision\n",
      "14  2007-08-21-0  2007-08-21-0/pipeline_classification/data000  000    vision\n",
      "15  2007-09-18-3  2007-09-18-3/pipeline_classification/data000  000    vision\n",
      "16  2007-09-18-6                          2007-09-18-6/data000  000    vision\n",
      "17  2008-03-25-3  2008-03-25-3/pipeline_classification/data000  000    vision\n",
      "18  2008-03-25-4  2008-03-25-4/pipeline_classification/data004  004    vision\n",
      "19  2008-08-27-1  2008-08-27-1/pipeline_classification/data002  002    vision\n",
      "20  2008-08-27-6  2008-08-27-6/pipeline_classification/data000  000    vision\n",
      "21  2008-11-12-1         2008-11-12-1/kilosort_data004/data004  004  kilosort\n",
      "22  2009-02-28-1         2009-02-28-1/kilosort_data005/data005  005  kilosort\n",
      "23  2009-04-13-2         2009-04-13-2/kilosort_data004/data004  004  kilosort\n",
      "24  2009-04-13-3         2009-04-13-3/kilosort_data012/data012  012  kilosort\n",
      "25  2009-04-13-5  2009-04-13-5/pipeline_classification/data008  008    vision\n",
      "26  2010-09-24-2                          2010-09-24-2/data001  001    vision\n",
      "27  2012-01-27-0  2012-01-27-0/pipeline_classification/data000  000    vision\n",
      "28  2012-04-13-4  2012-04-13-4/pipeline_classification/data000  000    vision\n",
      "29  2012-09-13-1  2012-09-13-1/pipeline_classification/data000  000    vision\n",
      "30  2012-09-24-2  2012-09-24-2/pipeline_classification/data000  000    vision\n",
      "31  2012-09-24-3  2012-09-24-3/pipeline_classification/data000  000    vision\n",
      "32  2012-09-27-3  2012-09-27-3/pipeline_classification/data003  003    vision\n",
      "33  2013-01-28-0         2013-01-28-0/kilosort_data001/data001  001  kilosort\n",
      "34  2013-05-28-4  2013-05-28-4/pipeline_classification/data000  000    vision\n",
      "35  2013-08-19-6  2013-08-19-6/pipeline_classification/data000  000    vision\n",
      "36  2014-09-10-2                      2014-09-10-2/data000-agg  000    vision\n",
      "37  2014-11-24-3  2014-11-24-3/pipeline_classification/data012  012    vision\n",
      "38  2015-03-09-0  2015-03-09-0/pipeline_classification/data000  000    vision\n",
      "39  2015-05-27-4  2015-05-27-4/pipeline_classification/data000  000    vision\n",
      "40  2015-09-23-2  2015-09-23-2/pipeline_classification/data000  000    vision\n",
      "41  2015-10-06-3  2015-10-06-3/pipeline_classification/data000  000    vision\n",
      "42  2015-11-09-3  2015-11-09-3/pipeline_classification/data000  000    vision\n",
      "43  2016-01-05-0  2016-01-05-0/pipeline_classification/data001  001    vision\n",
      "44  2016-06-13-1         2016-06-13-1/kilosort_data007/data007  007  kilosort\n",
      "45  2017-03-15-1         2017-03-15-1/kilosort_data000/data000  000  kilosort\n",
      "46  2017-04-25-0         2017-04-25-0/kilosort_data001/data001  001  kilosort\n",
      "47  2017-08-14-1          2017-08-14-1/data000-data001/data000  000    vision\n",
      "48  2017-10-30-6                          2017-10-30-6/data001  001    vision\n",
      "49  2017-10-30-7                      2017-10-30-7/data000-agg  000    vision\n",
      "50  2018-02-06-4                      2018-02-06-4/data000-agg  000    vision\n",
      "51  2018-03-01-0         2018-03-01-0/kilosort_data000/data000  000  kilosort\n",
      "52  2018-03-01-6          2018-03-01-6/data001-data003/data001  001    vision\n",
      "53  2018-11-12-0                      2018-11-12-0/data000-agg  000    vision\n",
      "54  2018-11-12-5                          2018-11-12-5/data003  003    vision\n",
      "55  2019-02-27-1                          2019-02-27-1/data000  000    vision\n",
      "56  2019-11-07-0                          2019-11-07-0/data000  000    vision\n",
      "57  2022-05-16-3                 2022-05-16-3/streamed/data005  005    vision\n"
     ]
    }
   ],
   "source": [
    "# Gorish + Publishable Level Test Sets (512-array, vision)\n",
    "dtlist = pd.read_csv('testval_sets.csv')\n",
    "dtlist.columns = ['piece','path']\n",
    "dtlist['run'] = '000' # Recording of interest\n",
    "dtlist['sorter'] = 'vision' # Spike sorter used\n",
    "# Create dataframe of pieces with paths, runs, and sorter specified (necessary info for initializing cell table)\n",
    "for ind in range(len(dtlist)):\n",
    "    dtlist.run[ind] = re.search(r'\\d+', dtlist.path[ind][::-1]).group()[::-1]\n",
    "    if 'kilosort' in dtlist.path[ind]:\n",
    "        dtlist.sorter[ind] = 'kilosort'\n",
    "    elif 'yass' in dtlist.path[ind]:\n",
    "        dtlist.sorter[ind] = 'yass'\n",
    "\n",
    "print(dtlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9fd446-00ac-4e3f-a267-d4225a2018d2",
   "metadata": {},
   "source": [
    "## Set Up Dataset_Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2297c6d8-0387-433b-a2fa-0bfc315bb547",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up 58 pieces\n",
      "Missing 50-frame STA /Volumes/Scratch/Users/alexth/supersample-stas/2012-09-24-3/kilosort_data000/data000/data000.wu_sta\n",
      "Missing long EI /Volumes/Scratch/Users/alexth/supersample-stas/2012-09-24-3/kilosort_data000/data000/data000.ei\n",
      "Missing 50-frame STA /Volumes/Scratch/Users/alexth/supersample-stas/2015-09-23-2/kilosort_data000/data000/data000.wu_sta\n",
      "Missing long EI /Volumes/Scratch/Users/alexth/supersample-stas/2015-09-23-2/kilosort_data000/data000/data000.ei\n",
      "Missing 50-frame STA /Volumes/Scratch/Users/alexth/supersample-stas/2015-10-06-3/kilosort_data000/data000/data000.wu_sta\n",
      "Missing long EI /Volumes/Scratch/Users/alexth/supersample-stas/2015-10-06-3/kilosort_data000/data000/data000.ei\n",
      "Missing 50-frame STA /Volumes/Scratch/Users/alexth/supersample-stas/2015-11-09-3/kilosort_data000/data000/data000.wu_sta\n",
      "Missing long EI /Volumes/Scratch/Users/alexth/supersample-stas/2015-11-09-3/kilosort_data000/data000/data000.ei\n",
      "Missing 50-frame STA /Volumes/Scratch/Users/alexth/supersample-stas/2022-05-16-3/kilosort_data005/data005/data005.wu_sta\n",
      "Missing long EI /Volumes/Scratch/Users/alexth/supersample-stas/2022-05-16-3/kilosort_data005/data005/data005.ei\n"
     ]
    }
   ],
   "source": [
    "# The dataset_table holds information about the datasets we want to work with, both their input properties (path)\n",
    "# and their analysis (retinal location, animal, temperature, etc). First we make it outside the CellTable, then we let the CellTable\n",
    "# hold it and take over\n",
    "\n",
    "# Set up standard information for creating dataset_table for input into cell_table\n",
    "print(f'Setting up {len(dtlist)} pieces')\n",
    "index = []\n",
    "dataset_dict = cdl.new_dataset_dict()\n",
    "\n",
    "# Run through our initial dataframe and fill in information for each piece\n",
    "for ind, row in dtlist.iterrows():\n",
    "    piece_id, run_id = dtlist.piece[ind], dtlist.run[ind]\n",
    "    path = (f'/Volumes/Analysis/' + dtlist.path[ind])\n",
    "    if not os.path.isdir(path):\n",
    "        print(f'Missing main vision analysis data {path}')\n",
    "        continue\n",
    "    label_mode, label_data_path, sta_path, ei_path = cdl.make_paths(piece_id, run_id) #Paths for labels made\n",
    "    ei_path = '' #Do not use supersampled EI's (standard is fine)\n",
    "    dataset_dict['run_id'].append(run_id) #Recording of interest\n",
    "    dataset_dict['piece_id'].append(piece_id) #Piece of retina\n",
    "    dataset_dict['note'].append('novel') \n",
    "    dataset_dict['path'].append(path) #Where the analysis lives\n",
    "    dataset_dict['labels'].append(label_mode) #Labels for cell types\n",
    "    dataset_dict['sorter'].append(dtlist.sorter[ind]) #Spike sorter used\n",
    "    dataset_dict['label_data_path'].append(label_data_path) #Where labels live\n",
    "    dataset_dict['sta_path'].append(sta_path) #Where visual stim lives (we will not be using this)\n",
    "    dataset_dict['ei_path'].append(ei_path) #Where EI lives\n",
    "    dataset_dict['stimulus_type'].append('whitenoise') #The type of visual stim used\n",
    "    dataset_dict['species'].append('macaque') #Animal used\n",
    "    index.append((piece_id, run_id))\n",
    "\n",
    "\n",
    "dataset_table = pd.DataFrame(dataset_dict, index=pd.MultiIndex.from_tuples(index, names=['piece_id','run_id']))\n",
    "\n",
    "# display(dataset_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e85f99ca-ab8b-4944-be33-7a3be7045c9d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>sorter</th>\n",
       "      <th>labels</th>\n",
       "      <th>piece_id</th>\n",
       "      <th>path</th>\n",
       "      <th>note</th>\n",
       "      <th>label_data_path</th>\n",
       "      <th>sta_path</th>\n",
       "      <th>ei_path</th>\n",
       "      <th>stimulus_type</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piece_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2005-04-06-0</th>\n",
       "      <th>001</th>\n",
       "      <td>001</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2005-04-06-0</td>\n",
       "      <td>/Volumes/Analysis/2005-04-06-0/data001</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2005-04-06-0/kilosort_data001/data001/data001.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-06-4</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2005-04-06-4</td>\n",
       "      <td>/Volumes/Analysis/2005-04-06-4/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2005-04-06-4/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-26-0</th>\n",
       "      <th>002</th>\n",
       "      <td>002</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2005-04-26-0</td>\n",
       "      <td>/Volumes/Analysis/2005-04-26-0/pipeline_classification/data002</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2005-04-26-0/kilosort_data002/data002/data002.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-07-26-4</th>\n",
       "      <th>001</th>\n",
       "      <td>001</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2005-07-26-4</td>\n",
       "      <td>/Volumes/Analysis/2005-07-26-4/pipeline_classification/data001</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2005-07-26-4/kilosort_data001/data001/data001.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-05-04-0</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2006-05-04-0</td>\n",
       "      <td>/Volumes/Analysis/2006-05-04-0/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2006-05-04-0/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-07-14-1</th>\n",
       "      <th>012</th>\n",
       "      <td>012</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2006-07-14-1</td>\n",
       "      <td>/Volumes/Analysis/2006-07-14-1/pipeline_classification/data012</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2006-07-14-1/kilosort_data012/data012/data012.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-11-01-4</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2006-11-01-4</td>\n",
       "      <td>/Volumes/Analysis/2006-11-01-4/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2006-11-01-4/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-06-1</th>\n",
       "      <th>015</th>\n",
       "      <td>015</td>\n",
       "      <td>kilosort</td>\n",
       "      <td>vision</td>\n",
       "      <td>2007-02-06-1</td>\n",
       "      <td>/Volumes/Analysis/2007-02-06-1/kilosort_data015/data015</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2007-02-06-1/kilosort_data015/data015/data015.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-06-4</th>\n",
       "      <th>015</th>\n",
       "      <td>015</td>\n",
       "      <td>kilosort</td>\n",
       "      <td>vision</td>\n",
       "      <td>2007-02-06-4</td>\n",
       "      <td>/Volumes/Analysis/2007-02-06-4/kilosort_data015/data015</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2007-02-06-4/kilosort_data015/data015/data015.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-02-06-6</th>\n",
       "      <th>007</th>\n",
       "      <td>007</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2007-02-06-6</td>\n",
       "      <td>/Volumes/Analysis/2007-02-06-6/pipeline_classification/data007</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2007-02-06-6/kilosort_data007/data007/data007.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-02-0</th>\n",
       "      <th>015</th>\n",
       "      <td>015</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2007-03-02-0</td>\n",
       "      <td>/Volumes/Analysis/2007-03-02-0/pipeline_classification/data015</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2007-03-02-0/kilosort_data015/data015/data015.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-03-02-3</th>\n",
       "      <th>010</th>\n",
       "      <td>010</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2007-03-02-3</td>\n",
       "      <td>/Volumes/Analysis/2007-03-02-3/pipeline_classification/data010</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2007-03-02-3/kilosort_data010/data010/data010.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-08-21-0</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2007-08-21-0</td>\n",
       "      <td>/Volumes/Analysis/2007-08-21-0/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2007-08-21-0/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-18-3</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2007-09-18-3</td>\n",
       "      <td>/Volumes/Analysis/2007-09-18-3/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2007-09-18-3/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-09-18-6</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2007-09-18-6</td>\n",
       "      <td>/Volumes/Analysis/2007-09-18-6/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2007-09-18-6/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-25-3</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2008-03-25-3</td>\n",
       "      <td>/Volumes/Analysis/2008-03-25-3/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2008-03-25-3/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-03-25-4</th>\n",
       "      <th>004</th>\n",
       "      <td>004</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2008-03-25-4</td>\n",
       "      <td>/Volumes/Analysis/2008-03-25-4/pipeline_classification/data004</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2008-03-25-4/kilosort_data004/data004/data004.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-27-1</th>\n",
       "      <th>002</th>\n",
       "      <td>002</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2008-08-27-1</td>\n",
       "      <td>/Volumes/Analysis/2008-08-27-1/pipeline_classification/data002</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2008-08-27-1/kilosort_data002/data002/data002.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-08-27-6</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2008-08-27-6</td>\n",
       "      <td>/Volumes/Analysis/2008-08-27-6/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2008-08-27-6/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-11-12-1</th>\n",
       "      <th>004</th>\n",
       "      <td>004</td>\n",
       "      <td>kilosort</td>\n",
       "      <td>vision</td>\n",
       "      <td>2008-11-12-1</td>\n",
       "      <td>/Volumes/Analysis/2008-11-12-1/kilosort_data004/data004</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2008-11-12-1/kilosort_data004/data004/data004.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-02-28-1</th>\n",
       "      <th>005</th>\n",
       "      <td>005</td>\n",
       "      <td>kilosort</td>\n",
       "      <td>vision</td>\n",
       "      <td>2009-02-28-1</td>\n",
       "      <td>/Volumes/Analysis/2009-02-28-1/kilosort_data005/data005</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2009-02-28-1/kilosort_data005/data005/data005.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-13-2</th>\n",
       "      <th>004</th>\n",
       "      <td>004</td>\n",
       "      <td>kilosort</td>\n",
       "      <td>vision</td>\n",
       "      <td>2009-04-13-2</td>\n",
       "      <td>/Volumes/Analysis/2009-04-13-2/kilosort_data004/data004</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2009-04-13-2/kilosort_data004/data004/data004.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-13-3</th>\n",
       "      <th>012</th>\n",
       "      <td>012</td>\n",
       "      <td>kilosort</td>\n",
       "      <td>vision</td>\n",
       "      <td>2009-04-13-3</td>\n",
       "      <td>/Volumes/Analysis/2009-04-13-3/kilosort_data012/data012</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2009-04-13-3/kilosort_data012/data012/data012.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-13-5</th>\n",
       "      <th>008</th>\n",
       "      <td>008</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2009-04-13-5</td>\n",
       "      <td>/Volumes/Analysis/2009-04-13-5/pipeline_classification/data008</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2009-04-13-5/kilosort_data008/data008/data008.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-24-2</th>\n",
       "      <th>001</th>\n",
       "      <td>001</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2010-09-24-2</td>\n",
       "      <td>/Volumes/Analysis/2010-09-24-2/data001</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2010-09-24-2/kilosort_data001/data001/data001.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-27-0</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2012-01-27-0</td>\n",
       "      <td>/Volumes/Analysis/2012-01-27-0/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2012-01-27-0/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-04-13-4</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2012-04-13-4</td>\n",
       "      <td>/Volumes/Analysis/2012-04-13-4/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2012-04-13-4/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-13-1</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2012-09-13-1</td>\n",
       "      <td>/Volumes/Analysis/2012-09-13-1/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2012-09-13-1/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-24-2</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2012-09-24-2</td>\n",
       "      <td>/Volumes/Analysis/2012-09-24-2/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2012-09-24-2/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-24-3</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2012-09-24-3</td>\n",
       "      <td>/Volumes/Analysis/2012-09-24-3/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-09-27-3</th>\n",
       "      <th>003</th>\n",
       "      <td>003</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2012-09-27-3</td>\n",
       "      <td>/Volumes/Analysis/2012-09-27-3/pipeline_classification/data003</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2012-09-27-3/kilosort_data003/data003/data003.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-28-0</th>\n",
       "      <th>001</th>\n",
       "      <td>001</td>\n",
       "      <td>kilosort</td>\n",
       "      <td>vision</td>\n",
       "      <td>2013-01-28-0</td>\n",
       "      <td>/Volumes/Analysis/2013-01-28-0/kilosort_data001/data001</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2013-01-28-0/kilosort_data001/data001/data001.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-28-4</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2013-05-28-4</td>\n",
       "      <td>/Volumes/Analysis/2013-05-28-4/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2013-05-28-4/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-08-19-6</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2013-08-19-6</td>\n",
       "      <td>/Volumes/Analysis/2013-08-19-6/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2013-08-19-6/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-09-10-2</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2014-09-10-2</td>\n",
       "      <td>/Volumes/Analysis/2014-09-10-2/data000-agg</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2014-09-10-2/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-11-24-3</th>\n",
       "      <th>012</th>\n",
       "      <td>012</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2014-11-24-3</td>\n",
       "      <td>/Volumes/Analysis/2014-11-24-3/pipeline_classification/data012</td>\n",
       "      <td>novel</td>\n",
       "      <td>/Volumes/Analysis/2014-11-24-3/data012/data012.classification_agogliet.txt</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2014-11-24-3/kilosort_data012/data012/data012.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-09-0</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2015-03-09-0</td>\n",
       "      <td>/Volumes/Analysis/2015-03-09-0/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2015-03-09-0/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-05-27-4</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2015-05-27-4</td>\n",
       "      <td>/Volumes/Analysis/2015-05-27-4/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2015-05-27-4/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-23-2</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2015-09-23-2</td>\n",
       "      <td>/Volumes/Analysis/2015-09-23-2/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-10-06-3</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2015-10-06-3</td>\n",
       "      <td>/Volumes/Analysis/2015-10-06-3/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td>/Volumes/Analysis/2015-10-06-3/data000/data000.classification_agogliet.txt</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-09-3</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2015-11-09-3</td>\n",
       "      <td>/Volumes/Analysis/2015-11-09-3/pipeline_classification/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05-0</th>\n",
       "      <th>001</th>\n",
       "      <td>001</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2016-01-05-0</td>\n",
       "      <td>/Volumes/Analysis/2016-01-05-0/pipeline_classification/data001</td>\n",
       "      <td>novel</td>\n",
       "      <td>/Volumes/Analysis/2016-01-05-0/data001/data001.classification_agogliet.txt</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2016-01-05-0/kilosort_data001/data001/data001.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-13-1</th>\n",
       "      <th>007</th>\n",
       "      <td>007</td>\n",
       "      <td>kilosort</td>\n",
       "      <td>vision</td>\n",
       "      <td>2016-06-13-1</td>\n",
       "      <td>/Volumes/Analysis/2016-06-13-1/kilosort_data007/data007</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2016-06-13-1/kilosort_data007/data007/data007.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-15-1</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>kilosort</td>\n",
       "      <td>alexandra</td>\n",
       "      <td>2017-03-15-1</td>\n",
       "      <td>/Volumes/Analysis/2017-03-15-1/kilosort_data000/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/all_data/2017-03-15-1/all_ids_2017-03-15-1_grant.mat</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2017-03-15-1/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-25-0</th>\n",
       "      <th>001</th>\n",
       "      <td>001</td>\n",
       "      <td>kilosort</td>\n",
       "      <td>vision</td>\n",
       "      <td>2017-04-25-0</td>\n",
       "      <td>/Volumes/Analysis/2017-04-25-0/kilosort_data001/data001</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2017-04-25-0/kilosort_data001/data001/data001.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-14-1</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2017-08-14-1</td>\n",
       "      <td>/Volumes/Analysis/2017-08-14-1/data000-data001/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2017-08-14-1/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30-7</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2017-10-30-7</td>\n",
       "      <td>/Volumes/Analysis/2017-10-30-7/data000-agg</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2017-10-30-7/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06-4</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2018-02-06-4</td>\n",
       "      <td>/Volumes/Analysis/2018-02-06-4/data000-agg</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2018-02-06-4/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01-0</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>kilosort</td>\n",
       "      <td>alexandra</td>\n",
       "      <td>2018-03-01-0</td>\n",
       "      <td>/Volumes/Analysis/2018-03-01-0/kilosort_data000/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/all_data/2018-03-01-0/all_ids_2018-03-01-0_grant.mat</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2018-03-01-0/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-12-0</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>alexandra</td>\n",
       "      <td>2018-11-12-0</td>\n",
       "      <td>/Volumes/Analysis/2018-11-12-0/data000-agg</td>\n",
       "      <td>novel</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/all_data/2018-11-12-0/all_ids_2018-11-12-0_last.mat</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2018-11-12-0/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-12-5</th>\n",
       "      <th>003</th>\n",
       "      <td>003</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2018-11-12-5</td>\n",
       "      <td>/Volumes/Analysis/2018-11-12-5/data003</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2018-11-12-5/kilosort_data003/data003/data003.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-27-1</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>alexandra</td>\n",
       "      <td>2019-02-27-1</td>\n",
       "      <td>/Volumes/Analysis/2019-02-27-1/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/all_data/2019-02-27-1/all_ids_2019-02-27-1_last.mat</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2019-02-27-1/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07-0</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2019-11-07-0</td>\n",
       "      <td>/Volumes/Analysis/2019-11-07-0/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td>/Volumes/Analysis/2019-11-07-0/data000/data000.classification_agogliet.txt</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2019-11-07-0/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-16-3</th>\n",
       "      <th>005</th>\n",
       "      <td>005</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2022-05-16-3</td>\n",
       "      <td>/Volumes/Analysis/2022-05-16-3/streamed/data005</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    run_id    sorter     labels      piece_id  \\\n",
       "piece_id     run_id                                             \n",
       "2005-04-06-0 001       001    vision     vision  2005-04-06-0   \n",
       "2005-04-06-4 000       000    vision     vision  2005-04-06-4   \n",
       "2005-04-26-0 002       002    vision     vision  2005-04-26-0   \n",
       "2005-07-26-4 001       001    vision     vision  2005-07-26-4   \n",
       "2006-05-04-0 000       000    vision     vision  2006-05-04-0   \n",
       "2006-07-14-1 012       012    vision     vision  2006-07-14-1   \n",
       "2006-11-01-4 000       000    vision     vision  2006-11-01-4   \n",
       "2007-02-06-1 015       015  kilosort     vision  2007-02-06-1   \n",
       "2007-02-06-4 015       015  kilosort     vision  2007-02-06-4   \n",
       "2007-02-06-6 007       007    vision     vision  2007-02-06-6   \n",
       "2007-03-02-0 015       015    vision     vision  2007-03-02-0   \n",
       "2007-03-02-3 010       010    vision     vision  2007-03-02-3   \n",
       "2007-08-21-0 000       000    vision     vision  2007-08-21-0   \n",
       "2007-09-18-3 000       000    vision     vision  2007-09-18-3   \n",
       "2007-09-18-6 000       000    vision     vision  2007-09-18-6   \n",
       "2008-03-25-3 000       000    vision     vision  2008-03-25-3   \n",
       "2008-03-25-4 004       004    vision     vision  2008-03-25-4   \n",
       "2008-08-27-1 002       002    vision     vision  2008-08-27-1   \n",
       "2008-08-27-6 000       000    vision     vision  2008-08-27-6   \n",
       "2008-11-12-1 004       004  kilosort     vision  2008-11-12-1   \n",
       "2009-02-28-1 005       005  kilosort     vision  2009-02-28-1   \n",
       "2009-04-13-2 004       004  kilosort     vision  2009-04-13-2   \n",
       "2009-04-13-3 012       012  kilosort     vision  2009-04-13-3   \n",
       "2009-04-13-5 008       008    vision     vision  2009-04-13-5   \n",
       "2010-09-24-2 001       001    vision     vision  2010-09-24-2   \n",
       "2012-01-27-0 000       000    vision     vision  2012-01-27-0   \n",
       "2012-04-13-4 000       000    vision     vision  2012-04-13-4   \n",
       "2012-09-13-1 000       000    vision     vision  2012-09-13-1   \n",
       "2012-09-24-2 000       000    vision     vision  2012-09-24-2   \n",
       "2012-09-24-3 000       000    vision     vision  2012-09-24-3   \n",
       "2012-09-27-3 003       003    vision     vision  2012-09-27-3   \n",
       "2013-01-28-0 001       001  kilosort     vision  2013-01-28-0   \n",
       "2013-05-28-4 000       000    vision     vision  2013-05-28-4   \n",
       "2013-08-19-6 000       000    vision     vision  2013-08-19-6   \n",
       "2014-09-10-2 000       000    vision     vision  2014-09-10-2   \n",
       "2014-11-24-3 012       012    vision     vision  2014-11-24-3   \n",
       "2015-03-09-0 000       000    vision     vision  2015-03-09-0   \n",
       "2015-05-27-4 000       000    vision     vision  2015-05-27-4   \n",
       "2015-09-23-2 000       000    vision     vision  2015-09-23-2   \n",
       "2015-10-06-3 000       000    vision     vision  2015-10-06-3   \n",
       "2015-11-09-3 000       000    vision     vision  2015-11-09-3   \n",
       "2016-01-05-0 001       001    vision     vision  2016-01-05-0   \n",
       "2016-06-13-1 007       007  kilosort     vision  2016-06-13-1   \n",
       "2017-03-15-1 000       000  kilosort  alexandra  2017-03-15-1   \n",
       "2017-04-25-0 001       001  kilosort     vision  2017-04-25-0   \n",
       "2017-08-14-1 000       000    vision     vision  2017-08-14-1   \n",
       "2017-10-30-7 000       000    vision     vision  2017-10-30-7   \n",
       "2018-02-06-4 000       000    vision     vision  2018-02-06-4   \n",
       "2018-03-01-0 000       000  kilosort  alexandra  2018-03-01-0   \n",
       "2018-11-12-0 000       000    vision  alexandra  2018-11-12-0   \n",
       "2018-11-12-5 003       003    vision     vision  2018-11-12-5   \n",
       "2019-02-27-1 000       000    vision  alexandra  2019-02-27-1   \n",
       "2019-11-07-0 000       000    vision     vision  2019-11-07-0   \n",
       "2022-05-16-3 005       005    vision     vision  2022-05-16-3   \n",
       "\n",
       "                                                                               path  \\\n",
       "piece_id     run_id                                                                   \n",
       "2005-04-06-0 001                             /Volumes/Analysis/2005-04-06-0/data001   \n",
       "2005-04-06-4 000     /Volumes/Analysis/2005-04-06-4/pipeline_classification/data000   \n",
       "2005-04-26-0 002     /Volumes/Analysis/2005-04-26-0/pipeline_classification/data002   \n",
       "2005-07-26-4 001     /Volumes/Analysis/2005-07-26-4/pipeline_classification/data001   \n",
       "2006-05-04-0 000                             /Volumes/Analysis/2006-05-04-0/data000   \n",
       "2006-07-14-1 012     /Volumes/Analysis/2006-07-14-1/pipeline_classification/data012   \n",
       "2006-11-01-4 000                             /Volumes/Analysis/2006-11-01-4/data000   \n",
       "2007-02-06-1 015            /Volumes/Analysis/2007-02-06-1/kilosort_data015/data015   \n",
       "2007-02-06-4 015            /Volumes/Analysis/2007-02-06-4/kilosort_data015/data015   \n",
       "2007-02-06-6 007     /Volumes/Analysis/2007-02-06-6/pipeline_classification/data007   \n",
       "2007-03-02-0 015     /Volumes/Analysis/2007-03-02-0/pipeline_classification/data015   \n",
       "2007-03-02-3 010     /Volumes/Analysis/2007-03-02-3/pipeline_classification/data010   \n",
       "2007-08-21-0 000     /Volumes/Analysis/2007-08-21-0/pipeline_classification/data000   \n",
       "2007-09-18-3 000     /Volumes/Analysis/2007-09-18-3/pipeline_classification/data000   \n",
       "2007-09-18-6 000                             /Volumes/Analysis/2007-09-18-6/data000   \n",
       "2008-03-25-3 000     /Volumes/Analysis/2008-03-25-3/pipeline_classification/data000   \n",
       "2008-03-25-4 004     /Volumes/Analysis/2008-03-25-4/pipeline_classification/data004   \n",
       "2008-08-27-1 002     /Volumes/Analysis/2008-08-27-1/pipeline_classification/data002   \n",
       "2008-08-27-6 000     /Volumes/Analysis/2008-08-27-6/pipeline_classification/data000   \n",
       "2008-11-12-1 004            /Volumes/Analysis/2008-11-12-1/kilosort_data004/data004   \n",
       "2009-02-28-1 005            /Volumes/Analysis/2009-02-28-1/kilosort_data005/data005   \n",
       "2009-04-13-2 004            /Volumes/Analysis/2009-04-13-2/kilosort_data004/data004   \n",
       "2009-04-13-3 012            /Volumes/Analysis/2009-04-13-3/kilosort_data012/data012   \n",
       "2009-04-13-5 008     /Volumes/Analysis/2009-04-13-5/pipeline_classification/data008   \n",
       "2010-09-24-2 001                             /Volumes/Analysis/2010-09-24-2/data001   \n",
       "2012-01-27-0 000     /Volumes/Analysis/2012-01-27-0/pipeline_classification/data000   \n",
       "2012-04-13-4 000     /Volumes/Analysis/2012-04-13-4/pipeline_classification/data000   \n",
       "2012-09-13-1 000     /Volumes/Analysis/2012-09-13-1/pipeline_classification/data000   \n",
       "2012-09-24-2 000     /Volumes/Analysis/2012-09-24-2/pipeline_classification/data000   \n",
       "2012-09-24-3 000     /Volumes/Analysis/2012-09-24-3/pipeline_classification/data000   \n",
       "2012-09-27-3 003     /Volumes/Analysis/2012-09-27-3/pipeline_classification/data003   \n",
       "2013-01-28-0 001            /Volumes/Analysis/2013-01-28-0/kilosort_data001/data001   \n",
       "2013-05-28-4 000     /Volumes/Analysis/2013-05-28-4/pipeline_classification/data000   \n",
       "2013-08-19-6 000     /Volumes/Analysis/2013-08-19-6/pipeline_classification/data000   \n",
       "2014-09-10-2 000                         /Volumes/Analysis/2014-09-10-2/data000-agg   \n",
       "2014-11-24-3 012     /Volumes/Analysis/2014-11-24-3/pipeline_classification/data012   \n",
       "2015-03-09-0 000     /Volumes/Analysis/2015-03-09-0/pipeline_classification/data000   \n",
       "2015-05-27-4 000     /Volumes/Analysis/2015-05-27-4/pipeline_classification/data000   \n",
       "2015-09-23-2 000     /Volumes/Analysis/2015-09-23-2/pipeline_classification/data000   \n",
       "2015-10-06-3 000     /Volumes/Analysis/2015-10-06-3/pipeline_classification/data000   \n",
       "2015-11-09-3 000     /Volumes/Analysis/2015-11-09-3/pipeline_classification/data000   \n",
       "2016-01-05-0 001     /Volumes/Analysis/2016-01-05-0/pipeline_classification/data001   \n",
       "2016-06-13-1 007            /Volumes/Analysis/2016-06-13-1/kilosort_data007/data007   \n",
       "2017-03-15-1 000            /Volumes/Analysis/2017-03-15-1/kilosort_data000/data000   \n",
       "2017-04-25-0 001            /Volumes/Analysis/2017-04-25-0/kilosort_data001/data001   \n",
       "2017-08-14-1 000             /Volumes/Analysis/2017-08-14-1/data000-data001/data000   \n",
       "2017-10-30-7 000                         /Volumes/Analysis/2017-10-30-7/data000-agg   \n",
       "2018-02-06-4 000                         /Volumes/Analysis/2018-02-06-4/data000-agg   \n",
       "2018-03-01-0 000            /Volumes/Analysis/2018-03-01-0/kilosort_data000/data000   \n",
       "2018-11-12-0 000                         /Volumes/Analysis/2018-11-12-0/data000-agg   \n",
       "2018-11-12-5 003                             /Volumes/Analysis/2018-11-12-5/data003   \n",
       "2019-02-27-1 000                             /Volumes/Analysis/2019-02-27-1/data000   \n",
       "2019-11-07-0 000                             /Volumes/Analysis/2019-11-07-0/data000   \n",
       "2022-05-16-3 005                    /Volumes/Analysis/2022-05-16-3/streamed/data005   \n",
       "\n",
       "                      note  \\\n",
       "piece_id     run_id          \n",
       "2005-04-06-0 001     novel   \n",
       "2005-04-06-4 000     novel   \n",
       "2005-04-26-0 002     novel   \n",
       "2005-07-26-4 001     novel   \n",
       "2006-05-04-0 000     novel   \n",
       "2006-07-14-1 012     novel   \n",
       "2006-11-01-4 000     novel   \n",
       "2007-02-06-1 015     novel   \n",
       "2007-02-06-4 015     novel   \n",
       "2007-02-06-6 007     novel   \n",
       "2007-03-02-0 015     novel   \n",
       "2007-03-02-3 010     novel   \n",
       "2007-08-21-0 000     novel   \n",
       "2007-09-18-3 000     novel   \n",
       "2007-09-18-6 000     novel   \n",
       "2008-03-25-3 000     novel   \n",
       "2008-03-25-4 004     novel   \n",
       "2008-08-27-1 002     novel   \n",
       "2008-08-27-6 000     novel   \n",
       "2008-11-12-1 004     novel   \n",
       "2009-02-28-1 005     novel   \n",
       "2009-04-13-2 004     novel   \n",
       "2009-04-13-3 012     novel   \n",
       "2009-04-13-5 008     novel   \n",
       "2010-09-24-2 001     novel   \n",
       "2012-01-27-0 000     novel   \n",
       "2012-04-13-4 000     novel   \n",
       "2012-09-13-1 000     novel   \n",
       "2012-09-24-2 000     novel   \n",
       "2012-09-24-3 000     novel   \n",
       "2012-09-27-3 003     novel   \n",
       "2013-01-28-0 001     novel   \n",
       "2013-05-28-4 000     novel   \n",
       "2013-08-19-6 000     novel   \n",
       "2014-09-10-2 000     novel   \n",
       "2014-11-24-3 012     novel   \n",
       "2015-03-09-0 000     novel   \n",
       "2015-05-27-4 000     novel   \n",
       "2015-09-23-2 000     novel   \n",
       "2015-10-06-3 000     novel   \n",
       "2015-11-09-3 000     novel   \n",
       "2016-01-05-0 001     novel   \n",
       "2016-06-13-1 007     novel   \n",
       "2017-03-15-1 000     novel   \n",
       "2017-04-25-0 001     novel   \n",
       "2017-08-14-1 000     novel   \n",
       "2017-10-30-7 000     novel   \n",
       "2018-02-06-4 000     novel   \n",
       "2018-03-01-0 000     novel   \n",
       "2018-11-12-0 000     novel   \n",
       "2018-11-12-5 003     novel   \n",
       "2019-02-27-1 000     novel   \n",
       "2019-11-07-0 000     novel   \n",
       "2022-05-16-3 005     novel   \n",
       "\n",
       "                                                                                        label_data_path  \\\n",
       "piece_id     run_id                                                                                       \n",
       "2005-04-06-0 001                                                                                          \n",
       "2005-04-06-4 000                                                                                          \n",
       "2005-04-26-0 002                                                                                          \n",
       "2005-07-26-4 001                                                                                          \n",
       "2006-05-04-0 000                                                                                          \n",
       "2006-07-14-1 012                                                                                          \n",
       "2006-11-01-4 000                                                                                          \n",
       "2007-02-06-1 015                                                                                          \n",
       "2007-02-06-4 015                                                                                          \n",
       "2007-02-06-6 007                                                                                          \n",
       "2007-03-02-0 015                                                                                          \n",
       "2007-03-02-3 010                                                                                          \n",
       "2007-08-21-0 000                                                                                          \n",
       "2007-09-18-3 000                                                                                          \n",
       "2007-09-18-6 000                                                                                          \n",
       "2008-03-25-3 000                                                                                          \n",
       "2008-03-25-4 004                                                                                          \n",
       "2008-08-27-1 002                                                                                          \n",
       "2008-08-27-6 000                                                                                          \n",
       "2008-11-12-1 004                                                                                          \n",
       "2009-02-28-1 005                                                                                          \n",
       "2009-04-13-2 004                                                                                          \n",
       "2009-04-13-3 012                                                                                          \n",
       "2009-04-13-5 008                                                                                          \n",
       "2010-09-24-2 001                                                                                          \n",
       "2012-01-27-0 000                                                                                          \n",
       "2012-04-13-4 000                                                                                          \n",
       "2012-09-13-1 000                                                                                          \n",
       "2012-09-24-2 000                                                                                          \n",
       "2012-09-24-3 000                                                                                          \n",
       "2012-09-27-3 003                                                                                          \n",
       "2013-01-28-0 001                                                                                          \n",
       "2013-05-28-4 000                                                                                          \n",
       "2013-08-19-6 000                                                                                          \n",
       "2014-09-10-2 000                                                                                          \n",
       "2014-11-24-3 012             /Volumes/Analysis/2014-11-24-3/data012/data012.classification_agogliet.txt   \n",
       "2015-03-09-0 000                                                                                          \n",
       "2015-05-27-4 000                                                                                          \n",
       "2015-09-23-2 000                                                                                          \n",
       "2015-10-06-3 000             /Volumes/Analysis/2015-10-06-3/data000/data000.classification_agogliet.txt   \n",
       "2015-11-09-3 000                                                                                          \n",
       "2016-01-05-0 001             /Volumes/Analysis/2016-01-05-0/data001/data001.classification_agogliet.txt   \n",
       "2016-06-13-1 007                                                                                          \n",
       "2017-03-15-1 000     /Volumes/Scratch/Users/alexth/all_data/2017-03-15-1/all_ids_2017-03-15-1_grant.mat   \n",
       "2017-04-25-0 001                                                                                          \n",
       "2017-08-14-1 000                                                                                          \n",
       "2017-10-30-7 000                                                                                          \n",
       "2018-02-06-4 000                                                                                          \n",
       "2018-03-01-0 000     /Volumes/Scratch/Users/alexth/all_data/2018-03-01-0/all_ids_2018-03-01-0_grant.mat   \n",
       "2018-11-12-0 000      /Volumes/Scratch/Users/alexth/all_data/2018-11-12-0/all_ids_2018-11-12-0_last.mat   \n",
       "2018-11-12-5 003                                                                                          \n",
       "2019-02-27-1 000      /Volumes/Scratch/Users/alexth/all_data/2019-02-27-1/all_ids_2019-02-27-1_last.mat   \n",
       "2019-11-07-0 000             /Volumes/Analysis/2019-11-07-0/data000/data000.classification_agogliet.txt   \n",
       "2022-05-16-3 005                                                                                          \n",
       "\n",
       "                                                                                                                sta_path  \\\n",
       "piece_id     run_id                                                                                                        \n",
       "2005-04-06-0 001     /Volumes/Scratch/Users/alexth/supersample-stas/2005-04-06-0/kilosort_data001/data001/data001.wu_sta   \n",
       "2005-04-06-4 000     /Volumes/Scratch/Users/alexth/supersample-stas/2005-04-06-4/kilosort_data000/data000/data000.wu_sta   \n",
       "2005-04-26-0 002     /Volumes/Scratch/Users/alexth/supersample-stas/2005-04-26-0/kilosort_data002/data002/data002.wu_sta   \n",
       "2005-07-26-4 001     /Volumes/Scratch/Users/alexth/supersample-stas/2005-07-26-4/kilosort_data001/data001/data001.wu_sta   \n",
       "2006-05-04-0 000     /Volumes/Scratch/Users/alexth/supersample-stas/2006-05-04-0/kilosort_data000/data000/data000.wu_sta   \n",
       "2006-07-14-1 012     /Volumes/Scratch/Users/alexth/supersample-stas/2006-07-14-1/kilosort_data012/data012/data012.wu_sta   \n",
       "2006-11-01-4 000     /Volumes/Scratch/Users/alexth/supersample-stas/2006-11-01-4/kilosort_data000/data000/data000.wu_sta   \n",
       "2007-02-06-1 015     /Volumes/Scratch/Users/alexth/supersample-stas/2007-02-06-1/kilosort_data015/data015/data015.wu_sta   \n",
       "2007-02-06-4 015     /Volumes/Scratch/Users/alexth/supersample-stas/2007-02-06-4/kilosort_data015/data015/data015.wu_sta   \n",
       "2007-02-06-6 007     /Volumes/Scratch/Users/alexth/supersample-stas/2007-02-06-6/kilosort_data007/data007/data007.wu_sta   \n",
       "2007-03-02-0 015     /Volumes/Scratch/Users/alexth/supersample-stas/2007-03-02-0/kilosort_data015/data015/data015.wu_sta   \n",
       "2007-03-02-3 010     /Volumes/Scratch/Users/alexth/supersample-stas/2007-03-02-3/kilosort_data010/data010/data010.wu_sta   \n",
       "2007-08-21-0 000     /Volumes/Scratch/Users/alexth/supersample-stas/2007-08-21-0/kilosort_data000/data000/data000.wu_sta   \n",
       "2007-09-18-3 000     /Volumes/Scratch/Users/alexth/supersample-stas/2007-09-18-3/kilosort_data000/data000/data000.wu_sta   \n",
       "2007-09-18-6 000     /Volumes/Scratch/Users/alexth/supersample-stas/2007-09-18-6/kilosort_data000/data000/data000.wu_sta   \n",
       "2008-03-25-3 000     /Volumes/Scratch/Users/alexth/supersample-stas/2008-03-25-3/kilosort_data000/data000/data000.wu_sta   \n",
       "2008-03-25-4 004     /Volumes/Scratch/Users/alexth/supersample-stas/2008-03-25-4/kilosort_data004/data004/data004.wu_sta   \n",
       "2008-08-27-1 002     /Volumes/Scratch/Users/alexth/supersample-stas/2008-08-27-1/kilosort_data002/data002/data002.wu_sta   \n",
       "2008-08-27-6 000     /Volumes/Scratch/Users/alexth/supersample-stas/2008-08-27-6/kilosort_data000/data000/data000.wu_sta   \n",
       "2008-11-12-1 004     /Volumes/Scratch/Users/alexth/supersample-stas/2008-11-12-1/kilosort_data004/data004/data004.wu_sta   \n",
       "2009-02-28-1 005     /Volumes/Scratch/Users/alexth/supersample-stas/2009-02-28-1/kilosort_data005/data005/data005.wu_sta   \n",
       "2009-04-13-2 004     /Volumes/Scratch/Users/alexth/supersample-stas/2009-04-13-2/kilosort_data004/data004/data004.wu_sta   \n",
       "2009-04-13-3 012     /Volumes/Scratch/Users/alexth/supersample-stas/2009-04-13-3/kilosort_data012/data012/data012.wu_sta   \n",
       "2009-04-13-5 008     /Volumes/Scratch/Users/alexth/supersample-stas/2009-04-13-5/kilosort_data008/data008/data008.wu_sta   \n",
       "2010-09-24-2 001     /Volumes/Scratch/Users/alexth/supersample-stas/2010-09-24-2/kilosort_data001/data001/data001.wu_sta   \n",
       "2012-01-27-0 000     /Volumes/Scratch/Users/alexth/supersample-stas/2012-01-27-0/kilosort_data000/data000/data000.wu_sta   \n",
       "2012-04-13-4 000     /Volumes/Scratch/Users/alexth/supersample-stas/2012-04-13-4/kilosort_data000/data000/data000.wu_sta   \n",
       "2012-09-13-1 000     /Volumes/Scratch/Users/alexth/supersample-stas/2012-09-13-1/kilosort_data000/data000/data000.wu_sta   \n",
       "2012-09-24-2 000     /Volumes/Scratch/Users/alexth/supersample-stas/2012-09-24-2/kilosort_data000/data000/data000.wu_sta   \n",
       "2012-09-24-3 000                                                                                                           \n",
       "2012-09-27-3 003     /Volumes/Scratch/Users/alexth/supersample-stas/2012-09-27-3/kilosort_data003/data003/data003.wu_sta   \n",
       "2013-01-28-0 001     /Volumes/Scratch/Users/alexth/supersample-stas/2013-01-28-0/kilosort_data001/data001/data001.wu_sta   \n",
       "2013-05-28-4 000     /Volumes/Scratch/Users/alexth/supersample-stas/2013-05-28-4/kilosort_data000/data000/data000.wu_sta   \n",
       "2013-08-19-6 000     /Volumes/Scratch/Users/alexth/supersample-stas/2013-08-19-6/kilosort_data000/data000/data000.wu_sta   \n",
       "2014-09-10-2 000     /Volumes/Scratch/Users/alexth/supersample-stas/2014-09-10-2/kilosort_data000/data000/data000.wu_sta   \n",
       "2014-11-24-3 012     /Volumes/Scratch/Users/alexth/supersample-stas/2014-11-24-3/kilosort_data012/data012/data012.wu_sta   \n",
       "2015-03-09-0 000     /Volumes/Scratch/Users/alexth/supersample-stas/2015-03-09-0/kilosort_data000/data000/data000.wu_sta   \n",
       "2015-05-27-4 000     /Volumes/Scratch/Users/alexth/supersample-stas/2015-05-27-4/kilosort_data000/data000/data000.wu_sta   \n",
       "2015-09-23-2 000                                                                                                           \n",
       "2015-10-06-3 000                                                                                                           \n",
       "2015-11-09-3 000                                                                                                           \n",
       "2016-01-05-0 001     /Volumes/Scratch/Users/alexth/supersample-stas/2016-01-05-0/kilosort_data001/data001/data001.wu_sta   \n",
       "2016-06-13-1 007     /Volumes/Scratch/Users/alexth/supersample-stas/2016-06-13-1/kilosort_data007/data007/data007.wu_sta   \n",
       "2017-03-15-1 000     /Volumes/Scratch/Users/alexth/supersample-stas/2017-03-15-1/kilosort_data000/data000/data000.wu_sta   \n",
       "2017-04-25-0 001     /Volumes/Scratch/Users/alexth/supersample-stas/2017-04-25-0/kilosort_data001/data001/data001.wu_sta   \n",
       "2017-08-14-1 000     /Volumes/Scratch/Users/alexth/supersample-stas/2017-08-14-1/kilosort_data000/data000/data000.wu_sta   \n",
       "2017-10-30-7 000     /Volumes/Scratch/Users/alexth/supersample-stas/2017-10-30-7/kilosort_data000/data000/data000.wu_sta   \n",
       "2018-02-06-4 000     /Volumes/Scratch/Users/alexth/supersample-stas/2018-02-06-4/kilosort_data000/data000/data000.wu_sta   \n",
       "2018-03-01-0 000     /Volumes/Scratch/Users/alexth/supersample-stas/2018-03-01-0/kilosort_data000/data000/data000.wu_sta   \n",
       "2018-11-12-0 000     /Volumes/Scratch/Users/alexth/supersample-stas/2018-11-12-0/kilosort_data000/data000/data000.wu_sta   \n",
       "2018-11-12-5 003     /Volumes/Scratch/Users/alexth/supersample-stas/2018-11-12-5/kilosort_data003/data003/data003.wu_sta   \n",
       "2019-02-27-1 000     /Volumes/Scratch/Users/alexth/supersample-stas/2019-02-27-1/kilosort_data000/data000/data000.wu_sta   \n",
       "2019-11-07-0 000     /Volumes/Scratch/Users/alexth/supersample-stas/2019-11-07-0/kilosort_data000/data000/data000.wu_sta   \n",
       "2022-05-16-3 005                                                                                                           \n",
       "\n",
       "                    ei_path stimulus_type  species  \n",
       "piece_id     run_id                                 \n",
       "2005-04-06-0 001               whitenoise  macaque  \n",
       "2005-04-06-4 000               whitenoise  macaque  \n",
       "2005-04-26-0 002               whitenoise  macaque  \n",
       "2005-07-26-4 001               whitenoise  macaque  \n",
       "2006-05-04-0 000               whitenoise  macaque  \n",
       "2006-07-14-1 012               whitenoise  macaque  \n",
       "2006-11-01-4 000               whitenoise  macaque  \n",
       "2007-02-06-1 015               whitenoise  macaque  \n",
       "2007-02-06-4 015               whitenoise  macaque  \n",
       "2007-02-06-6 007               whitenoise  macaque  \n",
       "2007-03-02-0 015               whitenoise  macaque  \n",
       "2007-03-02-3 010               whitenoise  macaque  \n",
       "2007-08-21-0 000               whitenoise  macaque  \n",
       "2007-09-18-3 000               whitenoise  macaque  \n",
       "2007-09-18-6 000               whitenoise  macaque  \n",
       "2008-03-25-3 000               whitenoise  macaque  \n",
       "2008-03-25-4 004               whitenoise  macaque  \n",
       "2008-08-27-1 002               whitenoise  macaque  \n",
       "2008-08-27-6 000               whitenoise  macaque  \n",
       "2008-11-12-1 004               whitenoise  macaque  \n",
       "2009-02-28-1 005               whitenoise  macaque  \n",
       "2009-04-13-2 004               whitenoise  macaque  \n",
       "2009-04-13-3 012               whitenoise  macaque  \n",
       "2009-04-13-5 008               whitenoise  macaque  \n",
       "2010-09-24-2 001               whitenoise  macaque  \n",
       "2012-01-27-0 000               whitenoise  macaque  \n",
       "2012-04-13-4 000               whitenoise  macaque  \n",
       "2012-09-13-1 000               whitenoise  macaque  \n",
       "2012-09-24-2 000               whitenoise  macaque  \n",
       "2012-09-24-3 000               whitenoise  macaque  \n",
       "2012-09-27-3 003               whitenoise  macaque  \n",
       "2013-01-28-0 001               whitenoise  macaque  \n",
       "2013-05-28-4 000               whitenoise  macaque  \n",
       "2013-08-19-6 000               whitenoise  macaque  \n",
       "2014-09-10-2 000               whitenoise  macaque  \n",
       "2014-11-24-3 012               whitenoise  macaque  \n",
       "2015-03-09-0 000               whitenoise  macaque  \n",
       "2015-05-27-4 000               whitenoise  macaque  \n",
       "2015-09-23-2 000               whitenoise  macaque  \n",
       "2015-10-06-3 000               whitenoise  macaque  \n",
       "2015-11-09-3 000               whitenoise  macaque  \n",
       "2016-01-05-0 001               whitenoise  macaque  \n",
       "2016-06-13-1 007               whitenoise  macaque  \n",
       "2017-03-15-1 000               whitenoise  macaque  \n",
       "2017-04-25-0 001               whitenoise  macaque  \n",
       "2017-08-14-1 000               whitenoise  macaque  \n",
       "2017-10-30-7 000               whitenoise  macaque  \n",
       "2018-02-06-4 000               whitenoise  macaque  \n",
       "2018-03-01-0 000               whitenoise  macaque  \n",
       "2018-11-12-0 000               whitenoise  macaque  \n",
       "2018-11-12-5 003               whitenoise  macaque  \n",
       "2019-02-27-1 000               whitenoise  macaque  \n",
       "2019-11-07-0 000               whitenoise  macaque  \n",
       "2022-05-16-3 005               whitenoise  macaque  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop rows of the array which throw dependency errors (missing data)\n",
    "pd.options.display.max_rows = 4000\n",
    "dataset_table = dataset_table.drop(index=('2006-05-04-2')) #Array Error\n",
    "dataset_table = dataset_table.drop(index=('2006-11-01-2')) #No EI\n",
    "dataset_table = dataset_table.drop(index=('2017-10-30-6')) #Label Issue\n",
    "dataset_table = dataset_table.drop(index=('2018-03-01-6')) #Label Issue\n",
    "display(dataset_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b8d5251-3f49-4a0f-a96e-5a7b233e6acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Welcome to the CellTable ~experience~\n",
      "~ \n",
      "~ Starting a fresh new CellTable\n"
     ]
    }
   ],
   "source": [
    "# The CellTable lives in Cell Display Lib, a module full of functions that are useful for cell data handling\n",
    "importlib.reload(cdl)\n",
    "ct = cdl.CellTable()  # Initialize the core object, called the CellTable spelled 'ct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d21bd7ed-f328-44b9-937a-effd0c35d008",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Adding 9 datasets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>sorter</th>\n",
       "      <th>labels</th>\n",
       "      <th>piece_id</th>\n",
       "      <th>path</th>\n",
       "      <th>note</th>\n",
       "      <th>label_data_path</th>\n",
       "      <th>sta_path</th>\n",
       "      <th>ei_path</th>\n",
       "      <th>stimulus_type</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piece_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-14-1</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2017-08-14-1</td>\n",
       "      <td>/Volumes/Analysis/2017-08-14-1/data000-data001/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2017-08-14-1/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30-7</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2017-10-30-7</td>\n",
       "      <td>/Volumes/Analysis/2017-10-30-7/data000-agg</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2017-10-30-7/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06-4</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2018-02-06-4</td>\n",
       "      <td>/Volumes/Analysis/2018-02-06-4/data000-agg</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2018-02-06-4/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01-0</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>kilosort</td>\n",
       "      <td>alexandra</td>\n",
       "      <td>2018-03-01-0</td>\n",
       "      <td>/Volumes/Analysis/2018-03-01-0/kilosort_data000/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/all_data/2018-03-01-0/all_ids_2018-03-01-0_grant.mat</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2018-03-01-0/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-12-0</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>alexandra</td>\n",
       "      <td>2018-11-12-0</td>\n",
       "      <td>/Volumes/Analysis/2018-11-12-0/data000-agg</td>\n",
       "      <td>novel</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/all_data/2018-11-12-0/all_ids_2018-11-12-0_last.mat</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2018-11-12-0/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-12-5</th>\n",
       "      <th>003</th>\n",
       "      <td>003</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2018-11-12-5</td>\n",
       "      <td>/Volumes/Analysis/2018-11-12-5/data003</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2018-11-12-5/kilosort_data003/data003/data003.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-27-1</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>alexandra</td>\n",
       "      <td>2019-02-27-1</td>\n",
       "      <td>/Volumes/Analysis/2019-02-27-1/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/all_data/2019-02-27-1/all_ids_2019-02-27-1_last.mat</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2019-02-27-1/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-07-0</th>\n",
       "      <th>000</th>\n",
       "      <td>000</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2019-11-07-0</td>\n",
       "      <td>/Volumes/Analysis/2019-11-07-0/data000</td>\n",
       "      <td>novel</td>\n",
       "      <td>/Volumes/Analysis/2019-11-07-0/data000/data000.classification_agogliet.txt</td>\n",
       "      <td>/Volumes/Scratch/Users/alexth/supersample-stas/2019-11-07-0/kilosort_data000/data000/data000.wu_sta</td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-16-3</th>\n",
       "      <th>005</th>\n",
       "      <td>005</td>\n",
       "      <td>vision</td>\n",
       "      <td>vision</td>\n",
       "      <td>2022-05-16-3</td>\n",
       "      <td>/Volumes/Analysis/2022-05-16-3/streamed/data005</td>\n",
       "      <td>novel</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>whitenoise</td>\n",
       "      <td>macaque</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    run_id    sorter     labels      piece_id  \\\n",
       "piece_id     run_id                                             \n",
       "2017-08-14-1 000       000    vision     vision  2017-08-14-1   \n",
       "2017-10-30-7 000       000    vision     vision  2017-10-30-7   \n",
       "2018-02-06-4 000       000    vision     vision  2018-02-06-4   \n",
       "2018-03-01-0 000       000  kilosort  alexandra  2018-03-01-0   \n",
       "2018-11-12-0 000       000    vision  alexandra  2018-11-12-0   \n",
       "2018-11-12-5 003       003    vision     vision  2018-11-12-5   \n",
       "2019-02-27-1 000       000    vision  alexandra  2019-02-27-1   \n",
       "2019-11-07-0 000       000    vision     vision  2019-11-07-0   \n",
       "2022-05-16-3 005       005    vision     vision  2022-05-16-3   \n",
       "\n",
       "                                                                        path  \\\n",
       "piece_id     run_id                                                            \n",
       "2017-08-14-1 000      /Volumes/Analysis/2017-08-14-1/data000-data001/data000   \n",
       "2017-10-30-7 000                  /Volumes/Analysis/2017-10-30-7/data000-agg   \n",
       "2018-02-06-4 000                  /Volumes/Analysis/2018-02-06-4/data000-agg   \n",
       "2018-03-01-0 000     /Volumes/Analysis/2018-03-01-0/kilosort_data000/data000   \n",
       "2018-11-12-0 000                  /Volumes/Analysis/2018-11-12-0/data000-agg   \n",
       "2018-11-12-5 003                      /Volumes/Analysis/2018-11-12-5/data003   \n",
       "2019-02-27-1 000                      /Volumes/Analysis/2019-02-27-1/data000   \n",
       "2019-11-07-0 000                      /Volumes/Analysis/2019-11-07-0/data000   \n",
       "2022-05-16-3 005             /Volumes/Analysis/2022-05-16-3/streamed/data005   \n",
       "\n",
       "                      note  \\\n",
       "piece_id     run_id          \n",
       "2017-08-14-1 000     novel   \n",
       "2017-10-30-7 000     novel   \n",
       "2018-02-06-4 000     novel   \n",
       "2018-03-01-0 000     novel   \n",
       "2018-11-12-0 000     novel   \n",
       "2018-11-12-5 003     novel   \n",
       "2019-02-27-1 000     novel   \n",
       "2019-11-07-0 000     novel   \n",
       "2022-05-16-3 005     novel   \n",
       "\n",
       "                                                                                        label_data_path  \\\n",
       "piece_id     run_id                                                                                       \n",
       "2017-08-14-1 000                                                                                          \n",
       "2017-10-30-7 000                                                                                          \n",
       "2018-02-06-4 000                                                                                          \n",
       "2018-03-01-0 000     /Volumes/Scratch/Users/alexth/all_data/2018-03-01-0/all_ids_2018-03-01-0_grant.mat   \n",
       "2018-11-12-0 000      /Volumes/Scratch/Users/alexth/all_data/2018-11-12-0/all_ids_2018-11-12-0_last.mat   \n",
       "2018-11-12-5 003                                                                                          \n",
       "2019-02-27-1 000      /Volumes/Scratch/Users/alexth/all_data/2019-02-27-1/all_ids_2019-02-27-1_last.mat   \n",
       "2019-11-07-0 000             /Volumes/Analysis/2019-11-07-0/data000/data000.classification_agogliet.txt   \n",
       "2022-05-16-3 005                                                                                          \n",
       "\n",
       "                                                                                                                sta_path  \\\n",
       "piece_id     run_id                                                                                                        \n",
       "2017-08-14-1 000     /Volumes/Scratch/Users/alexth/supersample-stas/2017-08-14-1/kilosort_data000/data000/data000.wu_sta   \n",
       "2017-10-30-7 000     /Volumes/Scratch/Users/alexth/supersample-stas/2017-10-30-7/kilosort_data000/data000/data000.wu_sta   \n",
       "2018-02-06-4 000     /Volumes/Scratch/Users/alexth/supersample-stas/2018-02-06-4/kilosort_data000/data000/data000.wu_sta   \n",
       "2018-03-01-0 000     /Volumes/Scratch/Users/alexth/supersample-stas/2018-03-01-0/kilosort_data000/data000/data000.wu_sta   \n",
       "2018-11-12-0 000     /Volumes/Scratch/Users/alexth/supersample-stas/2018-11-12-0/kilosort_data000/data000/data000.wu_sta   \n",
       "2018-11-12-5 003     /Volumes/Scratch/Users/alexth/supersample-stas/2018-11-12-5/kilosort_data003/data003/data003.wu_sta   \n",
       "2019-02-27-1 000     /Volumes/Scratch/Users/alexth/supersample-stas/2019-02-27-1/kilosort_data000/data000/data000.wu_sta   \n",
       "2019-11-07-0 000     /Volumes/Scratch/Users/alexth/supersample-stas/2019-11-07-0/kilosort_data000/data000/data000.wu_sta   \n",
       "2022-05-16-3 005                                                                                                           \n",
       "\n",
       "                    ei_path stimulus_type  species  \n",
       "piece_id     run_id                                 \n",
       "2017-08-14-1 000               whitenoise  macaque  \n",
       "2017-10-30-7 000               whitenoise  macaque  \n",
       "2018-02-06-4 000               whitenoise  macaque  \n",
       "2018-03-01-0 000               whitenoise  macaque  \n",
       "2018-11-12-0 000               whitenoise  macaque  \n",
       "2018-11-12-5 003               whitenoise  macaque  \n",
       "2019-02-27-1 000               whitenoise  macaque  \n",
       "2019-11-07-0 000               whitenoise  macaque  \n",
       "2022-05-16-3 005               whitenoise  macaque  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset_table we created into the ct (I do this in sections to protect against data loss in feature generation)\n",
    "dataset_ids = ct.add_datasets(dataset_table.iloc[45:, :])\n",
    "\n",
    "# The ct internal tables have pandas MultiIndexes as their indexes, so you use tuples to access individual rows\n",
    "# for the datasets, the tuples are ('piece_id','run_id')\n",
    "display(ct.dataset_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecbe9757-4f95-484c-b17b-e1d76f4b0827",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Loading new units from MultiIndex([('2017-08-14-1', '000'),\n",
      "            ('2017-10-30-7', '000'),\n",
      "            ('2018-02-06-4', '000'),\n",
      "            ('2018-03-01-0', '000'),\n",
      "            ('2018-11-12-0', '000'),\n",
      "            ('2018-11-12-5', '003'),\n",
      "            ('2019-02-27-1', '000'),\n",
      "            ('2019-11-07-0', '000'),\n",
      "            ('2022-05-16-3', '005')],\n",
      "           names=['piece_id', 'run_id']), currently have 9 datasets\n",
      "~ Starting with unit_table having 0 units\n",
      "~ Dataset ('2017-08-14-1', '000'): Loaded 380 units, sorter/alex indices 18 through 7611\n",
      "~ Dataset ('2017-10-30-7', '000'): Loaded 576 units, sorter/alex indices 16 through 7666\n",
      "~ Dataset ('2018-02-06-4', '000'): Loaded 603 units, sorter/alex indices 1 through 7669\n",
      "~ Dataset ('2018-03-01-0', '000'): Loaded 1160 units, sorter/alex indices 1 through 1669\n",
      "~ Dataset ('2018-11-12-0', '000'): Loaded 870 units, sorter/alex indices 1 through 7672\n",
      "~ Dataset ('2018-11-12-5', '003'): Loaded 576 units, sorter/alex indices 4 through 7672\n",
      "~ Dataset ('2019-02-27-1', '000'): Loaded 379 units, sorter/alex indices 3 through 7653\n",
      "~ Dataset ('2019-11-07-0', '000'): Loaded 690 units, sorter/alex indices 2 through 7668\n",
      "~ Dataset ('2022-05-16-3', '005'): Loaded 486 units, sorter/alex indices 35 through 7669\n",
      "~ done with dataset setup, now have 9 datasets, 5720 units\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultiIndex([('2017-08-14-1', '000'),\n",
       "            ('2017-10-30-7', '000'),\n",
       "            ('2018-02-06-4', '000'),\n",
       "            ('2018-03-01-0', '000'),\n",
       "            ('2018-11-12-0', '000'),\n",
       "            ('2018-11-12-5', '003'),\n",
       "            ('2019-02-27-1', '000'),\n",
       "            ('2019-11-07-0', '000'),\n",
       "            ('2022-05-16-3', '005')],\n",
       "           names=['piece_id', 'run_id'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize units (neurons detected) for each dataset\n",
    "ct.initialize_units_for_datasets(dataset_ids)\n",
    "\n",
    "# let's look at the unit_table, where most of the analysis is stored, which we have just filled with one row for every unit.\n",
    "# Each unit is also indexed by a tuple: ('piece_id','run_id','unit_id'), the last of which is the familiar Vision ID,\n",
    "# the output from the spike sorter. Note that these are not consecutive, but might be arranged on the electrode array.\n",
    "# the table also has columns 'unit_id' and 'dataset_id' for easy access later and to keep things organized\n",
    "# the column 'valid' is for excluding cells with basic errors, like having no spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7fead5ef-edda-4fd2-9903-0dc8893ef07a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Activating per-dataset features [\"<class 'features.Feature_load_manual_labels'>\", \"<class 'features.Feature_load_dataset_metadata'>\", \"<class 'features_electrical.Feature_load_spike_times'>\", \"<class 'features_electrical.Feature_spikes_basic'>\", \"<class 'features_electrical.Feature_load_ei'>\", \"<class 'features_electrical.Feature_generate_acf_from_spikes'>\", \"<class 'features_electrical.Feature_spike_waveform'>\", \"<class 'features_electrical.Feature_ei_correlation_data'>\", \"<class 'features_electrical.Feature_ei_select_electrodes'>\", \"<class 'features_electrical.Feature_ei_map'>\", \"<class 'features_DLelec.Feature_int_piece_id'>\", \"<class 'features_DLelec.Feature_spec_spike_waveform'>\", \"<class 'features_DLelec.Feature_spec_acf'>\", \"<class 'features_DLelec.Feature_retinal_eccentricity'>\", \"<class 'features_DLelec.Feature_map_early_ei_char'>\", \"<class 'features_DLelec.Feature_spike_char'>\", \"<class 'features_DLelec.Feature_axon_vel'>\"]\n",
      "*** timer  started\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2017-08-14-1', '000'), 1 of 7\n",
      "Loading vision data (thanks Eric), using load_sta False and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "*** elapsed 0s of 0s = 0.0m elapsed, of 0.0m estimated (1/7) (3.9 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2017-10-30-7', '000'), 2 of 7\n",
      "Loading vision data (thanks Eric), using load_sta False and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "*** elapsed 0s of 1s = 0.0m elapsed, of 0.0m estimated (2/7) (3.2 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2018-02-06-4', '000'), 3 of 7\n",
      "Loading vision data (thanks Eric), using load_sta False and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "*** elapsed 0s of 1s = 0.0m elapsed, of 0.0m estimated (3/7) (3.2 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2018-03-01-0', '000'), 4 of 7\n",
      "Loading vision data (thanks Eric), using load_sta False and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "*** elapsed 1s of 1s = 0.0m elapsed, of 0.0m estimated (4/7) (2.7 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2018-11-12-5', '003'), 5 of 7\n",
      "Loading vision data (thanks Eric), using load_sta False and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "*** elapsed 1s of 2s = 0.0m elapsed, of 0.0m estimated (5/7) (2.3 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2019-11-07-0', '000'), 6 of 7\n",
      "Loading vision data (thanks Eric), using load_sta False and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "... loading manual labels via mode vision\n",
      "using vision types\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "... processed spikes, mean 11797 count by cell\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "... EI shape is (512, 65)\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "... Calculating ACF using 101 logarithmic bins, from 3.0 to 2581141.3 samples wide, from 20.0 to 20000000.0, density mode\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "...filtering EI variance variance log using 512 electrodes, 65 frames, 0.5 threshold\n",
      "...found 501 good, 11 bad electrodes\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "... formatting EI energy maps: 501/512 electrodes, 65 time frames, to rectangular 63 by 30\n",
      "done with 0 of 690\n",
      "done with 200 of 690\n",
      "done with 400 of 690\n",
      "done with 600 of 690\n",
      "... done formatting EI energy\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "*** elapsed 33s of 35s = 0.6m elapsed, of 0.7m estimated (6/7) (0.2 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2022-05-16-3', '005'), 7 of 7\n",
      "Loading vision data (thanks Eric), using load_sta True and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "... loading manual labels via mode vision\n",
      "using vision types\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "Run table query datarun == \"data005\" and Piece == \"2022-05-16-3\" failed\n",
      "Piece table query Date == \"2022-05-16-3\" failed\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "... processed spikes, mean 11659 count by cell\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "... EI shape is (512, 111)\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "... Calculating ACF using 101 logarithmic bins, from 3.0 to 2581141.3 samples wide, from 20.0 to 20000000.0, density mode\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "...filtering EI variance variance log using 512 electrodes, 111 frames, 0.5 threshold\n",
      "...found 416 good, 96 bad electrodes\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "... formatting EI energy maps: 416/512 electrodes, 111 time frames, to rectangular 63 by 30\n",
      "done with 0 of 486\n",
      "done with 200 of 486\n",
      "done with 400 of 486\n",
      "... done formatting EI energy\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... feature complete. unit_table has 4471 (4454 valid) entries, with 54 columns\n",
      "*** elapsed 39s of 74s = 1.2m elapsed, of 1.2m estimated (7/7) (0.1 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "*** elapsed 0s of 74s = 1.2m elapsed\n",
      "~ Enabling: [process manual labels] v1 by Sam provides {'unit': set()}, requires {'unit': set()}\n",
      "...Using label source label_manual_text_input\n",
      "... Found 86 cell types, storing label_manual_uniquenames in ct.pdict\n",
      "*** elapsed 0s of 74s = 1.2m elapsed\n",
      "~ \n",
      "All done generating features! Congrats & be well\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>piece_id</th>\n",
       "      <th>valid</th>\n",
       "      <th>label_manual_text_input</th>\n",
       "      <th>spike_times</th>\n",
       "      <th>spike_count</th>\n",
       "      <th>spike_duration</th>\n",
       "      <th>spike_rate_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>spike_area_amp_lower</th>\n",
       "      <th>spike_area_tr_amp_upper</th>\n",
       "      <th>spike_area_tr_amp_lower</th>\n",
       "      <th>spike_slope_amp_upper</th>\n",
       "      <th>spike_slope_amp_lower</th>\n",
       "      <th>spike_area2</th>\n",
       "      <th>spike_width_half_max_amp</th>\n",
       "      <th>axon_vel</th>\n",
       "      <th>alex_id</th>\n",
       "      <th>label_manual_input</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piece_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>unit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2017-08-14-1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">000</th>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>(2017-08-14-1, 000)</td>\n",
       "      <td>000</td>\n",
       "      <td>2017-08-14-1</td>\n",
       "      <td>True</td>\n",
       "      <td>ON midget</td>\n",
       "      <td>a14433</td>\n",
       "      <td>14433.0</td>\n",
       "      <td>1799.92845</td>\n",
       "      <td>8.018652</td>\n",
       "      <td>...</td>\n",
       "      <td>3485.350342</td>\n",
       "      <td>3512.150379</td>\n",
       "      <td>3359.448189</td>\n",
       "      <td>8.852301</td>\n",
       "      <td>9.254678</td>\n",
       "      <td>9250.087891</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62.0</td>\n",
       "      <td>(2017-08-14-1, 000)</td>\n",
       "      <td>000</td>\n",
       "      <td>2017-08-14-1</td>\n",
       "      <td>True</td>\n",
       "      <td>OFF parasol</td>\n",
       "      <td>a8948</td>\n",
       "      <td>8948.0</td>\n",
       "      <td>1799.95995</td>\n",
       "      <td>4.971222</td>\n",
       "      <td>...</td>\n",
       "      <td>2416.339355</td>\n",
       "      <td>2565.691086</td>\n",
       "      <td>2332.446442</td>\n",
       "      <td>7.068020</td>\n",
       "      <td>7.774821</td>\n",
       "      <td>9786.713867</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77.0</td>\n",
       "      <td>(2017-08-14-1, 000)</td>\n",
       "      <td>000</td>\n",
       "      <td>2017-08-14-1</td>\n",
       "      <td>True</td>\n",
       "      <td>ON midget</td>\n",
       "      <td>a9119</td>\n",
       "      <td>9119.0</td>\n",
       "      <td>1799.98045</td>\n",
       "      <td>5.066166</td>\n",
       "      <td>...</td>\n",
       "      <td>3974.444092</td>\n",
       "      <td>4564.326393</td>\n",
       "      <td>3888.129890</td>\n",
       "      <td>8.348105</td>\n",
       "      <td>9.799949</td>\n",
       "      <td>10104.735352</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136.0</td>\n",
       "      <td>(2017-08-14-1, 000)</td>\n",
       "      <td>000</td>\n",
       "      <td>2017-08-14-1</td>\n",
       "      <td>True</td>\n",
       "      <td>ON midget</td>\n",
       "      <td>a12535</td>\n",
       "      <td>12535.0</td>\n",
       "      <td>1799.99850</td>\n",
       "      <td>6.963895</td>\n",
       "      <td>...</td>\n",
       "      <td>1474.529785</td>\n",
       "      <td>1547.922409</td>\n",
       "      <td>1433.261490</td>\n",
       "      <td>2.831134</td>\n",
       "      <td>3.057625</td>\n",
       "      <td>4007.094238</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172.0</td>\n",
       "      <td>(2017-08-14-1, 000)</td>\n",
       "      <td>000</td>\n",
       "      <td>2017-08-14-1</td>\n",
       "      <td>True</td>\n",
       "      <td>OFF parasol</td>\n",
       "      <td>a8399</td>\n",
       "      <td>8399.0</td>\n",
       "      <td>1799.98465</td>\n",
       "      <td>4.666151</td>\n",
       "      <td>...</td>\n",
       "      <td>2220.546875</td>\n",
       "      <td>2456.817879</td>\n",
       "      <td>2136.363373</td>\n",
       "      <td>6.192358</td>\n",
       "      <td>7.121211</td>\n",
       "      <td>6984.326660</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022-05-16-3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">005</th>\n",
       "      <th>7636</th>\n",
       "      <td>7636.0</td>\n",
       "      <td>(2022-05-16-3, 005)</td>\n",
       "      <td>005</td>\n",
       "      <td>2022-05-16-3</td>\n",
       "      <td>True</td>\n",
       "      <td>ON parasol</td>\n",
       "      <td>a12029</td>\n",
       "      <td>12029.0</td>\n",
       "      <td>899.85945</td>\n",
       "      <td>13.367643</td>\n",
       "      <td>...</td>\n",
       "      <td>198.412460</td>\n",
       "      <td>345.099664</td>\n",
       "      <td>207.059798</td>\n",
       "      <td>2.045035</td>\n",
       "      <td>3.408392</td>\n",
       "      <td>264.043884</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.067218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>(2022-05-16-3, 005)</td>\n",
       "      <td>005</td>\n",
       "      <td>2022-05-16-3</td>\n",
       "      <td>True</td>\n",
       "      <td>OFF parasol</td>\n",
       "      <td>a9161</td>\n",
       "      <td>9161.0</td>\n",
       "      <td>899.93030</td>\n",
       "      <td>10.179677</td>\n",
       "      <td>...</td>\n",
       "      <td>791.723572</td>\n",
       "      <td>929.272442</td>\n",
       "      <td>760.313816</td>\n",
       "      <td>2.559979</td>\n",
       "      <td>3.128863</td>\n",
       "      <td>1726.214355</td>\n",
       "      <td>85.0</td>\n",
       "      <td>77.471309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>7655.0</td>\n",
       "      <td>(2022-05-16-3, 005)</td>\n",
       "      <td>005</td>\n",
       "      <td>2022-05-16-3</td>\n",
       "      <td>True</td>\n",
       "      <td>crap</td>\n",
       "      <td>a14047</td>\n",
       "      <td>14047.0</td>\n",
       "      <td>899.85000</td>\n",
       "      <td>15.610380</td>\n",
       "      <td>...</td>\n",
       "      <td>280.282654</td>\n",
       "      <td>452.121368</td>\n",
       "      <td>282.575855</td>\n",
       "      <td>2.354799</td>\n",
       "      <td>3.767678</td>\n",
       "      <td>262.880310</td>\n",
       "      <td>15.0</td>\n",
       "      <td>73.196644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667</th>\n",
       "      <td>7667.0</td>\n",
       "      <td>(2022-05-16-3, 005)</td>\n",
       "      <td>005</td>\n",
       "      <td>2022-05-16-3</td>\n",
       "      <td>True</td>\n",
       "      <td>ON parasol</td>\n",
       "      <td>a12692</td>\n",
       "      <td>12692.0</td>\n",
       "      <td>899.98420</td>\n",
       "      <td>14.102470</td>\n",
       "      <td>...</td>\n",
       "      <td>682.787170</td>\n",
       "      <td>782.153435</td>\n",
       "      <td>664.830420</td>\n",
       "      <td>2.607178</td>\n",
       "      <td>3.067268</td>\n",
       "      <td>1524.838501</td>\n",
       "      <td>99.0</td>\n",
       "      <td>77.168354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669</th>\n",
       "      <td>7669.0</td>\n",
       "      <td>(2022-05-16-3, 005)</td>\n",
       "      <td>005</td>\n",
       "      <td>2022-05-16-3</td>\n",
       "      <td>True</td>\n",
       "      <td>OFF parasol</td>\n",
       "      <td>a6308</td>\n",
       "      <td>6308.0</td>\n",
       "      <td>899.92950</td>\n",
       "      <td>7.009438</td>\n",
       "      <td>...</td>\n",
       "      <td>864.612732</td>\n",
       "      <td>1222.793507</td>\n",
       "      <td>846.549351</td>\n",
       "      <td>2.411822</td>\n",
       "      <td>3.483742</td>\n",
       "      <td>2415.016113</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4471 rows  55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             unit_id           dataset_id run_id  \\\n",
       "piece_id     run_id unit_id                                        \n",
       "2017-08-14-1 000    18          18.0  (2017-08-14-1, 000)    000   \n",
       "                    62          62.0  (2017-08-14-1, 000)    000   \n",
       "                    77          77.0  (2017-08-14-1, 000)    000   \n",
       "                    136        136.0  (2017-08-14-1, 000)    000   \n",
       "                    172        172.0  (2017-08-14-1, 000)    000   \n",
       "...                              ...                  ...    ...   \n",
       "2022-05-16-3 005    7636      7636.0  (2022-05-16-3, 005)    005   \n",
       "                    7642      7642.0  (2022-05-16-3, 005)    005   \n",
       "                    7655      7655.0  (2022-05-16-3, 005)    005   \n",
       "                    7667      7667.0  (2022-05-16-3, 005)    005   \n",
       "                    7669      7669.0  (2022-05-16-3, 005)    005   \n",
       "\n",
       "                                 piece_id valid label_manual_text_input  \\\n",
       "piece_id     run_id unit_id                                               \n",
       "2017-08-14-1 000    18       2017-08-14-1  True               ON midget   \n",
       "                    62       2017-08-14-1  True             OFF parasol   \n",
       "                    77       2017-08-14-1  True               ON midget   \n",
       "                    136      2017-08-14-1  True               ON midget   \n",
       "                    172      2017-08-14-1  True             OFF parasol   \n",
       "...                                   ...   ...                     ...   \n",
       "2022-05-16-3 005    7636     2022-05-16-3  True              ON parasol   \n",
       "                    7642     2022-05-16-3  True             OFF parasol   \n",
       "                    7655     2022-05-16-3  True                    crap   \n",
       "                    7667     2022-05-16-3  True              ON parasol   \n",
       "                    7669     2022-05-16-3  True             OFF parasol   \n",
       "\n",
       "                            spike_times  spike_count  spike_duration  \\\n",
       "piece_id     run_id unit_id                                            \n",
       "2017-08-14-1 000    18           a14433      14433.0      1799.92845   \n",
       "                    62            a8948       8948.0      1799.95995   \n",
       "                    77            a9119       9119.0      1799.98045   \n",
       "                    136          a12535      12535.0      1799.99850   \n",
       "                    172           a8399       8399.0      1799.98465   \n",
       "...                                 ...          ...             ...   \n",
       "2022-05-16-3 005    7636         a12029      12029.0       899.85945   \n",
       "                    7642          a9161       9161.0       899.93030   \n",
       "                    7655         a14047      14047.0       899.85000   \n",
       "                    7667         a12692      12692.0       899.98420   \n",
       "                    7669          a6308       6308.0       899.92950   \n",
       "\n",
       "                             spike_rate_mean  ... spike_area_amp_lower  \\\n",
       "piece_id     run_id unit_id                   ...                        \n",
       "2017-08-14-1 000    18              8.018652  ...          3485.350342   \n",
       "                    62              4.971222  ...          2416.339355   \n",
       "                    77              5.066166  ...          3974.444092   \n",
       "                    136             6.963895  ...          1474.529785   \n",
       "                    172             4.666151  ...          2220.546875   \n",
       "...                                      ...  ...                  ...   \n",
       "2022-05-16-3 005    7636           13.367643  ...           198.412460   \n",
       "                    7642           10.179677  ...           791.723572   \n",
       "                    7655           15.610380  ...           280.282654   \n",
       "                    7667           14.102470  ...           682.787170   \n",
       "                    7669            7.009438  ...           864.612732   \n",
       "\n",
       "                            spike_area_tr_amp_upper spike_area_tr_amp_lower  \\\n",
       "piece_id     run_id unit_id                                                   \n",
       "2017-08-14-1 000    18                  3512.150379             3359.448189   \n",
       "                    62                  2565.691086             2332.446442   \n",
       "                    77                  4564.326393             3888.129890   \n",
       "                    136                 1547.922409             1433.261490   \n",
       "                    172                 2456.817879             2136.363373   \n",
       "...                                             ...                     ...   \n",
       "2022-05-16-3 005    7636                 345.099664              207.059798   \n",
       "                    7642                 929.272442              760.313816   \n",
       "                    7655                 452.121368              282.575855   \n",
       "                    7667                 782.153435              664.830420   \n",
       "                    7669                1222.793507              846.549351   \n",
       "\n",
       "                            spike_slope_amp_upper spike_slope_amp_lower  \\\n",
       "piece_id     run_id unit_id                                               \n",
       "2017-08-14-1 000    18                   8.852301              9.254678   \n",
       "                    62                   7.068020              7.774821   \n",
       "                    77                   8.348105              9.799949   \n",
       "                    136                  2.831134              3.057625   \n",
       "                    172                  6.192358              7.121211   \n",
       "...                                           ...                   ...   \n",
       "2022-05-16-3 005    7636                 2.045035              3.408392   \n",
       "                    7642                 2.559979              3.128863   \n",
       "                    7655                 2.354799              3.767678   \n",
       "                    7667                 2.607178              3.067268   \n",
       "                    7669                 2.411822              3.483742   \n",
       "\n",
       "                              spike_area2  spike_width_half_max_amp  \\\n",
       "piece_id     run_id unit_id                                           \n",
       "2017-08-14-1 000    18        9250.087891                     120.0   \n",
       "                    62        9786.713867                      94.0   \n",
       "                    77       10104.735352                     106.0   \n",
       "                    136       4007.094238                     106.0   \n",
       "                    172       6984.326660                      95.0   \n",
       "...                                   ...                       ...   \n",
       "2022-05-16-3 005    7636       264.043884                      17.0   \n",
       "                    7642      1726.214355                      85.0   \n",
       "                    7655       262.880310                      15.0   \n",
       "                    7667      1524.838501                      99.0   \n",
       "                    7669      2415.016113                      84.0   \n",
       "\n",
       "                              axon_vel alex_id label_manual_input  \n",
       "piece_id     run_id unit_id                                        \n",
       "2017-08-14-1 000    18        0.000000     NaN               45.0  \n",
       "                    62        0.000000     NaN               25.0  \n",
       "                    77        0.000000     NaN               45.0  \n",
       "                    136       0.000000     NaN               45.0  \n",
       "                    172       0.000000     NaN               25.0  \n",
       "...                                ...     ...                ...  \n",
       "2022-05-16-3 005    7636     83.067218     NaN               46.0  \n",
       "                    7642     77.471309     NaN               25.0  \n",
       "                    7655     73.196644     NaN               57.0  \n",
       "                    7667     77.168354     NaN               46.0  \n",
       "                    7669      0.000000     NaN               25.0  \n",
       "\n",
       "[4471 rows x 55 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Features are how we generate the parameters that each cell has, which we use for analysis.\n",
    "# We'll make our own feature in a later section\n",
    "\n",
    "# a list of all of the features we want to run per-dataset\n",
    "# each of these are subclasses of Feature\n",
    "features_to_generate_by_dataset = [\n",
    "    # general information\n",
    "    feat.Feature_load_manual_labels,\n",
    "    feat.Feature_load_dataset_metadata,\n",
    "\n",
    "    # electrical (features from EI & recording information alone)\n",
    "    feat_e.Feature_load_spike_times, feat_e.Feature_spikes_basic,\n",
    "    feat_e.Feature_load_ei,\n",
    "    feat_e.Feature_generate_acf_from_spikes,\n",
    "    feat_e.Feature_spike_waveform,\n",
    "    feat_e.Feature_ei_correlation_data,\n",
    "    feat_e.Feature_ei_select_electrodes,\n",
    "    feat_e.Feature_ei_map,\n",
    "\n",
    "    # new feature functions for deep learning\n",
    "    feat_dl.Feature_int_piece_id,\n",
    "    feat_dl.Feature_spec_spike_waveform,\n",
    "    feat_dl.Feature_spec_acf,\n",
    "    feat_dl.Feature_retinal_eccentricity,\n",
    "    feat_dl.Feature_map_early_ei_char,\n",
    "    feat_dl.Feature_spike_char,\n",
    "    feat_dl.Feature_axon_vel\n",
    "    \n",
    "]\n",
    "\n",
    "# and then one feature to run overall, which sorts out the manual labels from text into integers\n",
    "features_to_generate_overall = [feat.Feature_process_manual_labels]\n",
    "\n",
    "# if the ct is very large we'll drop the big columns like STA and EI to save disk space, as they can be\n",
    "# easily reloaded later as needed (we will not drop the big columns yet)\n",
    "drop_big_columns = ct.unit_table.shape[0] > 10000\n",
    "# Eventually remove ei because size varies depending on array and bins in calculation\n",
    "big_columns_per_dataset = ['ei']\n",
    "\n",
    "# now generate the features we listed above, and display the resulting units_table\n",
    "# check out all of those new columns, which you can use to make your analysis\n",
    "ct.generate_features('all', features_to_generate_by_dataset, features_to_generate_overall,\n",
    "                     force_features=False,\n",
    "                     load_analysis_data=True, #I changed this line\n",
    "                     ignore_errors=False,\n",
    "                     drop_big_columns=False,\n",
    "                     big_columns_per_dataset=big_columns_per_dataset)\n",
    "display(ct.unit_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87c44b9f-960e-4ea3-81e3-4cc58b0799e3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Piece 2017-08-14-1 has 380 units from 1 datasets\n",
      "Piece 2017-10-30-7 has 576 units from 1 datasets\n",
      "Piece 2018-02-06-4 has 603 units from 1 datasets\n",
      "Piece 2018-03-01-0 has 1160 units from 1 datasets\n",
      "Piece 2018-11-12-5 has 576 units from 1 datasets\n",
      "Piece 2019-11-07-0 has 690 units from 1 datasets\n",
      "Piece 2022-05-16-3 has 486 units from 1 datasets\n",
      "~ Created fresh new cell_table and reset unit_table links. Now, you may deduplicate.\n",
      "Deduplicating units into cells.\n",
      "~ Correlating EI between units\n",
      "*** timer  started\n",
      "\n",
      "Evaluating piece 2017-08-14-1 w/ 1 datasets, 380 units\n",
      "Map dim 512, wave dim 65. Correlating EI energy first.\n",
      "Correlating spike waveforms.\n",
      "~ ... piece 2017-08-14-1, correlated EI maps & spike waveforms from 380 units.\n",
      "*** elapsed 0s of 0s = 0.0m elapsed, of 0.0m estimated (1/7) (2.5 / sec)\n",
      "\n",
      "Evaluating piece 2017-10-30-7 w/ 1 datasets, 576 units\n",
      "Map dim 512, wave dim 65. Correlating EI energy first.\n",
      "Correlating spike waveforms.\n",
      "~ ... piece 2017-10-30-7, correlated EI maps & spike waveforms from 576 units.\n",
      "*** elapsed 1s of 2s = 0.0m elapsed, of 0.1m estimated (2/7) (1.3 / sec)\n",
      "\n",
      "Evaluating piece 2018-02-06-4 w/ 1 datasets, 603 units\n",
      "Map dim 512, wave dim 51. Correlating EI energy first.\n",
      "Correlating spike waveforms.\n",
      "~ ... piece 2018-02-06-4, correlated EI maps & spike waveforms from 603 units.\n",
      "*** elapsed 1s of 3s = 0.0m elapsed, of 0.1m estimated (3/7) (1.1 / sec)\n",
      "\n",
      "Evaluating piece 2018-03-01-0 w/ 1 datasets, 1160 units\n",
      "Map dim 512, wave dim 61. Correlating EI energy first.\n",
      "Correlating spike waveforms.\n",
      "~ ... piece 2018-03-01-0, correlated EI maps & spike waveforms from 1160 units.\n",
      "*** elapsed 4s of 7s = 0.1m elapsed, of 0.2m estimated (4/7) (0.6 / sec)\n",
      "\n",
      "Evaluating piece 2018-11-12-5 w/ 1 datasets, 576 units\n",
      "Map dim 512, wave dim 51. Correlating EI energy first.\n",
      "Correlating spike waveforms.\n",
      "~ ... piece 2018-11-12-5, correlated EI maps & spike waveforms from 576 units.\n",
      "*** elapsed 1s of 8s = 0.1m elapsed, of 0.2m estimated (5/7) (0.6 / sec)\n",
      "\n",
      "Evaluating piece 2019-11-07-0 w/ 1 datasets, 690 units\n",
      "Map dim 512, wave dim 65. Correlating EI energy first.\n",
      "Correlating spike waveforms.\n",
      "~ ... piece 2019-11-07-0, correlated EI maps & spike waveforms from 690 units.\n",
      "*** elapsed 1s of 9s = 0.2m elapsed, of 0.2m estimated (6/7) (0.7 / sec)\n",
      "\n",
      "Evaluating piece 2022-05-16-3 w/ 1 datasets, 486 units\n",
      "Map dim 512, wave dim 111. Correlating EI energy first.\n",
      "Correlating spike waveforms.\n",
      "~ ... piece 2022-05-16-3, correlated EI maps & spike waveforms from 486 units.\n",
      "*** elapsed 1s of 10s = 0.2m elapsed, of 0.2m estimated (7/7) (0.7 / sec)\n",
      "~ found 18429 NaN EI correlations\n",
      "~ Done. Calculated 1612493 EI & ACF correlations\n",
      "~ Applying heuristic to 1612493 correlations...\n",
      "~ Done. Found 319 pairs marked for merge\n",
      "~ MERGE TIME\n",
      "Only run after creating a fresh clean cell_table\n",
      "~ Starting units merging by correlation heuristic...\n",
      "~ Done. Cells table now has 4192 valid of 4471 entries\n",
      "Arranging units by run within cells, selecting nsem run\n",
      "~ Have 210 cells w/ merged units to process. Evaluating spike times, generating spike tables & unions...\n",
      "~ Actually, using simple mode, which just compares spike counts (should be smarter though)\n",
      "*** timer  started\n",
      "~ Done merging spike times. Heuristic columns added to cell_table.\n",
      "*** elapsed 0s of 0s = 0.0m elapsed, of 0.0m estimated (210/210) (781.2 / sec)\n",
      "~ Evaluating merge strategies for each cell\n",
      "~ Strategy results: Highest: 210, Join: 0, Unknown: 0\n",
      "~ Done merging cells, cell_table is now ready to use\n",
      "Shrinking invalid cells from cell_table, starting with 4471 rows\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[-2 -2 -2 ... -2 -2 -2] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ct.cell_table contains just the true unique cells in each piece, with integer indices\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# the CellTable has a decent deduplication algorithm implemented, which combines multiple units into single cells\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# if you don't care for deduplication, just don't run it. You will still need to initialize_cell_table though,\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# and you'll have one cell per unit.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m ct\u001b[38;5;241m.\u001b[39minitialize_cell_table()\n\u001b[0;32m----> 7\u001b[0m \u001b[43mdeduplication\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeduplicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_sta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_combine_unit_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m display(ct\u001b[38;5;241m.\u001b[39mcell_table)\n",
      "File \u001b[0;32m/Volumes/Lab/Users/scooler/classification/deduplication.py:32\u001b[0m, in \u001b[0;36mdeduplicate\u001b[0;34m(ct, use_sta, verbose, do_combine_unit_data, pieces)\u001b[0m\n\u001b[1;32m     30\u001b[0m evaluate_spike_merge(ct, show_plots\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m     31\u001b[0m arrange_units_within_cells(ct)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mshrink_cell_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_combine_unit_data:\n\u001b[1;32m     35\u001b[0m     combine_unit_data(ct)\n",
      "File \u001b[0;32m/Volumes/Lab/Users/scooler/classification/deduplication.py:753\u001b[0m, in \u001b[0;36mshrink_cell_table\u001b[0;34m(ct)\u001b[0m\n\u001b[1;32m    751\u001b[0m pieces \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mdataset_table\u001b[38;5;241m.\u001b[39mpiece_id\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m    752\u001b[0m valid_cells \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mcell_table\u001b[38;5;241m.\u001b[39mvalid\n\u001b[0;32m--> 753\u001b[0m invalid_cells \u001b[38;5;241m=\u001b[39m \u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcell_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mvalid_cells\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m    754\u001b[0m ct\u001b[38;5;241m.\u001b[39mcell_table \u001b[38;5;241m=\u001b[39m ct\u001b[38;5;241m.\u001b[39mcell_table\u001b[38;5;241m.\u001b[39mdrop(index\u001b[38;5;241m=\u001b[39minvalid_cells)\n\u001b[1;32m    756\u001b[0m cell_tables \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/Volumes/Lab/Development/miniconda-peggyo/envs/mads3/lib/python3.9/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Lab/Development/miniconda-peggyo/envs/mads3/lib/python3.9/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m/Volumes/Lab/Development/miniconda-peggyo/envs/mads3/lib/python3.9/site-packages/pandas/core/indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m )\n",
      "File \u001b[0;32m/Volumes/Lab/Development/miniconda-peggyo/envs/mads3/lib/python3.9/site-packages/pandas/core/indexing.py:1327\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1324\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1325\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1327\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m/Volumes/Lab/Development/miniconda-peggyo/envs/mads3/lib/python3.9/site-packages/pandas/core/indexes/multi.py:2587\u001b[0m, in \u001b[0;36mMultiIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   2584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keyarr) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(keyarr[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   2585\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_indexer_level_0(keyarr)\n\u001b[0;32m-> 2587\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[indexer], indexer\n\u001b[1;32m   2590\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, axis_name)\n",
      "File \u001b[0;32m/Volumes/Lab/Development/miniconda-peggyo/envs/mads3/lib/python3.9/site-packages/pandas/core/indexes/multi.py:2605\u001b[0m, in \u001b[0;36mMultiIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   2603\u001b[0m cmask \u001b[38;5;241m=\u001b[39m check \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cmask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m-> 2605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyarr[cmask]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2606\u001b[0m \u001b[38;5;66;03m# We get here when levels still contain values which are not\u001b[39;00m\n\u001b[1;32m   2607\u001b[0m \u001b[38;5;66;03m# actually in Index anymore\u001b[39;00m\n\u001b[1;32m   2608\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkeyarr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[-2 -2 -2 ... -2 -2 -2] not in index'"
     ]
    }
   ],
   "source": [
    "# ct.cell_table contains just the true unique cells in each piece, with integer indices\n",
    "# the CellTable has a decent deduplication algorithm implemented, which combines multiple units into single cells\n",
    "ct.initialize_cell_table()\n",
    "deduplication.deduplicate(ct, use_sta=False, do_combine_unit_data=False, verbose=False)\n",
    "\n",
    "display(ct.cell_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "425624e1-da5d-4bcb-ab04-7cd13b135492",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2005-04-06-0', 0)\n",
      "2005-04-06-0\n",
      "unit_id                                         17\n",
      "dataset_id                     (2005-04-06-0, 001)\n",
      "run_id                                         001\n",
      "piece_id                              2005-04-06-0\n",
      "valid                                         True\n",
      "label_manual_text_input                 ON parasol\n",
      "spike_times                                 a26746\n",
      "spike_count                                26746.0\n",
      "spike_duration                          1799.95545\n",
      "spike_rate_mean                          14.859257\n",
      "ei                                         a512x81\n",
      "acf                                           a100\n",
      "spike_waveform_maxenergy                       a81\n",
      "spike_waveform_maxamplitude                    a81\n",
      "spike_waveform_smart                           a81\n",
      "ei_edge                                      False\n",
      "ei_peak                                  79.430725\n",
      "ei_axon_only                                  True\n",
      "ei_energy_raw                                 a512\n",
      "map_ei_energy                               a63x30\n",
      "map_ei_energy_early                         a63x30\n",
      "map_ei_energy_late                          a63x30\n",
      "int_piece_id                           200504060.0\n",
      "int_run_id                                     1.0\n",
      "spec_spike_waveform                          a41x1\n",
      "spec_freq                                      a41\n",
      "spec_timeoverlap                                a1\n",
      "spec_acf                                     a51x1\n",
      "spec_freq_acf                                  a51\n",
      "spec_timeoverlap_acf                        0.0025\n",
      "retinal_eccentricity                           100\n",
      "total_energy_ptnorm                      -0.264204\n",
      "early_area                                    38.5\n",
      "early_peri                               69.334194\n",
      "early_centroid                            [38, 15]\n",
      "early_circularity                         0.100641\n",
      "soma_area                                      1.5\n",
      "soma_peri                                 5.414214\n",
      "soma_centroid                             [44, 11]\n",
      "soma_circularity                          0.643029\n",
      "spike_min_h                              81.567642\n",
      "spike_max_l                               50.55357\n",
      "spike_minmax_ratio                        0.619775\n",
      "spike_width_half_min_amp                      27.0\n",
      "spike_area_amp_upper                   1007.179688\n",
      "spike_area_amp_lower                    742.946472\n",
      "spike_area_tr_amp_upper                 917.635975\n",
      "spike_area_tr_amp_lower                  734.10878\n",
      "spike_slope_amp_upper                     5.437843\n",
      "spike_slope_amp_lower                     6.797304\n",
      "spike_area2                             733.975159\n",
      "spike_width_half_max_amp                      19.0\n",
      "axon_vel                                 81.143805\n",
      "label_manual_input                            32.0\n",
      "cell_id                          (2005-04-06-0, 0)\n",
      "label_manual_text                       ON parasol\n",
      "label_manual                                  32.0\n",
      "Name: (2005-04-06-0, 001, 17), dtype: object\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test it out if desired\n",
    "# let's select some ON parasols from the first dataset\n",
    "indices = ct.cell_selection(types=['ON parasol'])\n",
    "\n",
    "# Let's grab the first one and see what it has in there\n",
    "id = indices[0]\n",
    "print(id) # see the piece_id, cell_id\n",
    "cell = ct.get_cell(id)\n",
    "print(cell['piece_id'])\n",
    "print(cell)\n",
    "\n",
    "# Let's plot the ACF:\n",
    "plt.figure()\n",
    "plt.plot(cell['acf'].a)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "56f67f0d-6d8f-4ef9-b608-a646df530af2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Activating per-dataset features [\"<class 'features.Feature_load_manual_labels'>\", \"<class 'features.Feature_load_dataset_metadata'>\", \"<class 'features_electrical.Feature_load_spike_times'>\", \"<class 'features_electrical.Feature_spikes_basic'>\", \"<class 'features_electrical.Feature_load_ei'>\", \"<class 'features_electrical.Feature_generate_acf_from_spikes'>\", \"<class 'features_electrical.Feature_spike_waveform'>\", \"<class 'features_electrical.Feature_ei_correlation_data'>\", \"<class 'features_electrical.Feature_ei_select_electrodes'>\", \"<class 'features_electrical.Feature_ei_map'>\", \"<class 'features_DLelec.Feature_int_piece_id'>\", \"<class 'features_DLelec.Feature_spec_spike_waveform'>\", \"<class 'features_DLelec.Feature_spec_acf'>\", \"<class 'features_DLelec.Feature_retinal_eccentricity'>\", \"<class 'features_DLelec.Feature_map_early_ei_char'>\", \"<class 'features_DLelec.Feature_spike_char'>\", \"<class 'features_DLelec.Feature_axon_vel'>\"]\n",
      "*** timer  started\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2017-08-14-1', '000'), 1 of 7\n",
      "Loading vision data (thanks Eric), using load_sta False and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Dropped columns ['ei', 'alex_id', 'spike_times', 'spike_count', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_edge', 'ei_peak', 'ei_axon_only', 'ei_energy_raw', 'map_ei_energy', 'map_ei_energy_early', 'map_ei_energy_late']\n",
      "*** elapsed 0s of 0s = 0.0m elapsed, of 0.0m estimated (1/7) (3.1 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2017-10-30-7', '000'), 2 of 7\n",
      "Loading vision data (thanks Eric), using load_sta False and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Dropped columns []\n",
      "*** elapsed 0s of 1s = 0.0m elapsed, of 0.0m estimated (2/7) (2.8 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2018-02-06-4', '000'), 3 of 7\n",
      "Loading vision data (thanks Eric), using load_sta False and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Dropped columns []\n",
      "*** elapsed 0s of 1s = 0.0m elapsed, of 0.0m estimated (3/7) (2.8 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2018-03-01-0', '000'), 4 of 7\n",
      "Loading vision data (thanks Eric), using load_sta False and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Dropped columns []\n",
      "*** elapsed 1s of 2s = 0.0m elapsed, of 0.0m estimated (4/7) (2.4 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2018-11-12-5', '003'), 5 of 7\n",
      "Loading vision data (thanks Eric), using load_sta False and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Dropped columns []\n",
      "*** elapsed 0s of 2s = 0.0m elapsed, of 0.0m estimated (5/7) (2.5 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2019-11-07-0', '000'), 6 of 7\n",
      "Loading vision data (thanks Eric), using load_sta False and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Dropped columns []\n",
      "*** elapsed 0s of 2s = 0.0m elapsed, of 0.0m estimated (6/7) (2.5 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "~ \n",
      "\n",
      "Generating features for dataset ('2022-05-16-3', '005'), 7 of 7\n",
      "Loading vision data (thanks Eric), using load_sta True and load_labels True and load_long_ei False\n",
      "~ Feature: [load manual labels] v1 by Sam provides {'unit': {'label_manual_text_input'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load dataset metadata] v1 by Sam provides {'dataset': {'params_wn', 'display', 'location_angle', 'temperature', 'optics', 'location_eccentricity', 'lens'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike times] v1 by Sam provides {'unit': {'spike_times'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spikes basic] v1 by Sam provides {'unit': {'spike_count', 'spike_rate_mean', 'spike_duration'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [load ei] v1 by Sam provides {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}, requires {'unit': {'unit_id'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [acf from spike times] v1 by Sam provides {'unit': {'acf'}, 'dataset': {'acf_bins'}}, requires {'unit': {'spike_times'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike waveform] v1 by Sam provides {'unit': {'spike_waveform_maxamplitude', 'ei_edge', 'ei_axon_only', 'spike_waveform_maxenergy', 'spike_waveform_smart', 'ei_peak'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_locations'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [correlation data] v1 by Sam provides {'unit': {'ei_energy_raw'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei select electrodes] v1 by Sam provides {'dataset': {'ei_electrode_selection'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [ei map] v1 by Sam provides {'unit': {'map_ei_energy_late', 'map_ei_energy_early', 'map_ei_energy'}}, requires {'unit': {'ei'}, 'dataset': {'ei_electrode_selection'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [int_piece_id] v0 by Mads provides {'unit': {'int_run_id', 'int_piece_id'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_spike_waveform] v0 by Mads provides {'unit': {'spec_spike_waveform', 'spec_freq', 'spec_timeoverlap'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spec_acf] v0 by Mads provides {'unit': {'spec_freq_acf', 'spec_acf', 'spec_timeoverlap_acf'}}, requires {'unit': {'acf'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [retinal_eccentricity] v0 by Maddy provides {'unit': {'retinal_eccentricity'}}, requires {'dataset': set(), 'unit': set()}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [map_early_ei_char] v0 by Maddy provides {'unit': {'early_circularity', 'early_peri', 'soma_peri', 'early_area', 'total_energy_ptnorm', 'soma_circularity', 'early_centroid', 'soma_area', 'soma_centroid'}}, requires {'unit': {'map_ei_energy_early'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [spike_char] v0 by Maddy provides {'unit': {'spike_width_half_min_amp', 'spike_area_tr_amp_lower', 'spike_slope_amp_upper', 'spike_area_amp_upper', 'spike_slope_amp_lower', 'spike_area2', 'spike_minmax_ratio', 'spike_max_l', 'spike_area_tr_amp_upper', 'spike_min_h', 'spike_width_half_max_amp', 'spike_area_amp_lower'}}, requires {'unit': {'spike_waveform_maxamplitude'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Feature: [axon_vel] v0 by Maddy provides {'unit': {'axon_vel'}}, requires {'unit': {'ei'}}\n",
      "~ ... Feature results already present; skipping generation\n",
      "~ Dropped columns []\n",
      "*** elapsed 2s of 4s = 0.1m elapsed, of 0.1m estimated (7/7) (1.7 / sec)\n",
      ".:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:._.:*~*:.\n",
      "*** elapsed 0s of 4s = 0.1m elapsed\n",
      "~ Enabling: [process manual labels] v1 by Sam provides {'unit': set()}, requires {'unit': set()}\n",
      "...Using label source label_manual_text_input\n",
      "... Found 86 cell types, storing label_manual_uniquenames in ct.pdict\n",
      "~ Dropped columns [] gently\n",
      "*** elapsed 0s of 4s = 0.1m elapsed\n",
      "~ \n",
      "All done generating features! Congrats & be well\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>piece_id</th>\n",
       "      <th>valid</th>\n",
       "      <th>label_manual_text_input</th>\n",
       "      <th>spike_duration</th>\n",
       "      <th>spike_rate_mean</th>\n",
       "      <th>acf</th>\n",
       "      <th>spike_waveform_maxamplitude</th>\n",
       "      <th>...</th>\n",
       "      <th>spike_area_tr_amp_lower</th>\n",
       "      <th>spike_slope_amp_upper</th>\n",
       "      <th>spike_slope_amp_lower</th>\n",
       "      <th>spike_area2</th>\n",
       "      <th>spike_width_half_max_amp</th>\n",
       "      <th>axon_vel</th>\n",
       "      <th>label_manual_input</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>label_manual_text</th>\n",
       "      <th>label_manual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>piece_id</th>\n",
       "      <th>run_id</th>\n",
       "      <th>unit_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2017-08-14-1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">000</th>\n",
       "      <th>18</th>\n",
       "      <td>18.0</td>\n",
       "      <td>(2017-08-14-1, 000)</td>\n",
       "      <td>000</td>\n",
       "      <td>2017-08-14-1</td>\n",
       "      <td>True</td>\n",
       "      <td>ON midget</td>\n",
       "      <td>1799.92845</td>\n",
       "      <td>8.018652</td>\n",
       "      <td>a100</td>\n",
       "      <td>a65</td>\n",
       "      <td>...</td>\n",
       "      <td>3359.448189</td>\n",
       "      <td>8.852301</td>\n",
       "      <td>9.254678</td>\n",
       "      <td>9250.087891</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>(2017-08-14-1, 0)</td>\n",
       "      <td>ON midget</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>62.0</td>\n",
       "      <td>(2017-08-14-1, 000)</td>\n",
       "      <td>000</td>\n",
       "      <td>2017-08-14-1</td>\n",
       "      <td>True</td>\n",
       "      <td>OFF parasol</td>\n",
       "      <td>1799.95995</td>\n",
       "      <td>4.971222</td>\n",
       "      <td>a100</td>\n",
       "      <td>a65</td>\n",
       "      <td>...</td>\n",
       "      <td>2332.446442</td>\n",
       "      <td>7.068020</td>\n",
       "      <td>7.774821</td>\n",
       "      <td>9786.713867</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>(2017-08-14-1, 1)</td>\n",
       "      <td>OFF parasol</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>77.0</td>\n",
       "      <td>(2017-08-14-1, 000)</td>\n",
       "      <td>000</td>\n",
       "      <td>2017-08-14-1</td>\n",
       "      <td>True</td>\n",
       "      <td>ON midget</td>\n",
       "      <td>1799.98045</td>\n",
       "      <td>5.066166</td>\n",
       "      <td>a100</td>\n",
       "      <td>a65</td>\n",
       "      <td>...</td>\n",
       "      <td>3888.129890</td>\n",
       "      <td>8.348105</td>\n",
       "      <td>9.799949</td>\n",
       "      <td>10104.735352</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>(2017-08-14-1, 2)</td>\n",
       "      <td>ON midget</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>136.0</td>\n",
       "      <td>(2017-08-14-1, 000)</td>\n",
       "      <td>000</td>\n",
       "      <td>2017-08-14-1</td>\n",
       "      <td>True</td>\n",
       "      <td>ON midget</td>\n",
       "      <td>1799.99850</td>\n",
       "      <td>6.963895</td>\n",
       "      <td>a100</td>\n",
       "      <td>a65</td>\n",
       "      <td>...</td>\n",
       "      <td>1433.261490</td>\n",
       "      <td>2.831134</td>\n",
       "      <td>3.057625</td>\n",
       "      <td>4007.094238</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>(2017-08-14-1, 3)</td>\n",
       "      <td>ON midget</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172.0</td>\n",
       "      <td>(2017-08-14-1, 000)</td>\n",
       "      <td>000</td>\n",
       "      <td>2017-08-14-1</td>\n",
       "      <td>True</td>\n",
       "      <td>OFF parasol</td>\n",
       "      <td>1799.98465</td>\n",
       "      <td>4.666151</td>\n",
       "      <td>a100</td>\n",
       "      <td>a65</td>\n",
       "      <td>...</td>\n",
       "      <td>2136.363373</td>\n",
       "      <td>6.192358</td>\n",
       "      <td>7.121211</td>\n",
       "      <td>6984.326660</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>(2017-08-14-1, 4)</td>\n",
       "      <td>OFF parasol</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022-05-16-3</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">005</th>\n",
       "      <th>7636</th>\n",
       "      <td>7636.0</td>\n",
       "      <td>(2022-05-16-3, 005)</td>\n",
       "      <td>005</td>\n",
       "      <td>2022-05-16-3</td>\n",
       "      <td>True</td>\n",
       "      <td>ON parasol</td>\n",
       "      <td>899.85945</td>\n",
       "      <td>13.367643</td>\n",
       "      <td>a100</td>\n",
       "      <td>a111</td>\n",
       "      <td>...</td>\n",
       "      <td>207.059798</td>\n",
       "      <td>2.045035</td>\n",
       "      <td>3.408392</td>\n",
       "      <td>264.043884</td>\n",
       "      <td>17.0</td>\n",
       "      <td>83.067218</td>\n",
       "      <td>46.0</td>\n",
       "      <td>(2022-05-16-3, 481)</td>\n",
       "      <td>ON parasol</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7642</th>\n",
       "      <td>7642.0</td>\n",
       "      <td>(2022-05-16-3, 005)</td>\n",
       "      <td>005</td>\n",
       "      <td>2022-05-16-3</td>\n",
       "      <td>True</td>\n",
       "      <td>OFF parasol</td>\n",
       "      <td>899.93030</td>\n",
       "      <td>10.179677</td>\n",
       "      <td>a100</td>\n",
       "      <td>a111</td>\n",
       "      <td>...</td>\n",
       "      <td>760.313816</td>\n",
       "      <td>2.559979</td>\n",
       "      <td>3.128863</td>\n",
       "      <td>1726.214355</td>\n",
       "      <td>85.0</td>\n",
       "      <td>77.471309</td>\n",
       "      <td>25.0</td>\n",
       "      <td>(2022-05-16-3, 482)</td>\n",
       "      <td>OFF parasol</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7655</th>\n",
       "      <td>7655.0</td>\n",
       "      <td>(2022-05-16-3, 005)</td>\n",
       "      <td>005</td>\n",
       "      <td>2022-05-16-3</td>\n",
       "      <td>True</td>\n",
       "      <td>crap</td>\n",
       "      <td>899.85000</td>\n",
       "      <td>15.610380</td>\n",
       "      <td>a100</td>\n",
       "      <td>a111</td>\n",
       "      <td>...</td>\n",
       "      <td>282.575855</td>\n",
       "      <td>2.354799</td>\n",
       "      <td>3.767678</td>\n",
       "      <td>262.880310</td>\n",
       "      <td>15.0</td>\n",
       "      <td>73.196644</td>\n",
       "      <td>57.0</td>\n",
       "      <td>(2022-05-16-3, 483)</td>\n",
       "      <td>crap</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7667</th>\n",
       "      <td>7667.0</td>\n",
       "      <td>(2022-05-16-3, 005)</td>\n",
       "      <td>005</td>\n",
       "      <td>2022-05-16-3</td>\n",
       "      <td>True</td>\n",
       "      <td>ON parasol</td>\n",
       "      <td>899.98420</td>\n",
       "      <td>14.102470</td>\n",
       "      <td>a100</td>\n",
       "      <td>a111</td>\n",
       "      <td>...</td>\n",
       "      <td>664.830420</td>\n",
       "      <td>2.607178</td>\n",
       "      <td>3.067268</td>\n",
       "      <td>1524.838501</td>\n",
       "      <td>99.0</td>\n",
       "      <td>77.168354</td>\n",
       "      <td>46.0</td>\n",
       "      <td>(2022-05-16-3, 484)</td>\n",
       "      <td>ON parasol</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669</th>\n",
       "      <td>7669.0</td>\n",
       "      <td>(2022-05-16-3, 005)</td>\n",
       "      <td>005</td>\n",
       "      <td>2022-05-16-3</td>\n",
       "      <td>True</td>\n",
       "      <td>OFF parasol</td>\n",
       "      <td>899.92950</td>\n",
       "      <td>7.009438</td>\n",
       "      <td>a100</td>\n",
       "      <td>a111</td>\n",
       "      <td>...</td>\n",
       "      <td>846.549351</td>\n",
       "      <td>2.411822</td>\n",
       "      <td>3.483742</td>\n",
       "      <td>2415.016113</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>(2022-05-16-3, 485)</td>\n",
       "      <td>OFF parasol</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4471 rows  45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             unit_id           dataset_id run_id  \\\n",
       "piece_id     run_id unit_id                                        \n",
       "2017-08-14-1 000    18          18.0  (2017-08-14-1, 000)    000   \n",
       "                    62          62.0  (2017-08-14-1, 000)    000   \n",
       "                    77          77.0  (2017-08-14-1, 000)    000   \n",
       "                    136        136.0  (2017-08-14-1, 000)    000   \n",
       "                    172        172.0  (2017-08-14-1, 000)    000   \n",
       "...                              ...                  ...    ...   \n",
       "2022-05-16-3 005    7636      7636.0  (2022-05-16-3, 005)    005   \n",
       "                    7642      7642.0  (2022-05-16-3, 005)    005   \n",
       "                    7655      7655.0  (2022-05-16-3, 005)    005   \n",
       "                    7667      7667.0  (2022-05-16-3, 005)    005   \n",
       "                    7669      7669.0  (2022-05-16-3, 005)    005   \n",
       "\n",
       "                                 piece_id valid label_manual_text_input  \\\n",
       "piece_id     run_id unit_id                                               \n",
       "2017-08-14-1 000    18       2017-08-14-1  True               ON midget   \n",
       "                    62       2017-08-14-1  True             OFF parasol   \n",
       "                    77       2017-08-14-1  True               ON midget   \n",
       "                    136      2017-08-14-1  True               ON midget   \n",
       "                    172      2017-08-14-1  True             OFF parasol   \n",
       "...                                   ...   ...                     ...   \n",
       "2022-05-16-3 005    7636     2022-05-16-3  True              ON parasol   \n",
       "                    7642     2022-05-16-3  True             OFF parasol   \n",
       "                    7655     2022-05-16-3  True                    crap   \n",
       "                    7667     2022-05-16-3  True              ON parasol   \n",
       "                    7669     2022-05-16-3  True             OFF parasol   \n",
       "\n",
       "                             spike_duration  spike_rate_mean   acf  \\\n",
       "piece_id     run_id unit_id                                          \n",
       "2017-08-14-1 000    18           1799.92845         8.018652  a100   \n",
       "                    62           1799.95995         4.971222  a100   \n",
       "                    77           1799.98045         5.066166  a100   \n",
       "                    136          1799.99850         6.963895  a100   \n",
       "                    172          1799.98465         4.666151  a100   \n",
       "...                                     ...              ...   ...   \n",
       "2022-05-16-3 005    7636          899.85945        13.367643  a100   \n",
       "                    7642          899.93030        10.179677  a100   \n",
       "                    7655          899.85000        15.610380  a100   \n",
       "                    7667          899.98420        14.102470  a100   \n",
       "                    7669          899.92950         7.009438  a100   \n",
       "\n",
       "                            spike_waveform_maxamplitude  ...  \\\n",
       "piece_id     run_id unit_id                              ...   \n",
       "2017-08-14-1 000    18                              a65  ...   \n",
       "                    62                              a65  ...   \n",
       "                    77                              a65  ...   \n",
       "                    136                             a65  ...   \n",
       "                    172                             a65  ...   \n",
       "...                                                 ...  ...   \n",
       "2022-05-16-3 005    7636                           a111  ...   \n",
       "                    7642                           a111  ...   \n",
       "                    7655                           a111  ...   \n",
       "                    7667                           a111  ...   \n",
       "                    7669                           a111  ...   \n",
       "\n",
       "                             spike_area_tr_amp_lower  spike_slope_amp_upper  \\\n",
       "piece_id     run_id unit_id                                                   \n",
       "2017-08-14-1 000    18                   3359.448189               8.852301   \n",
       "                    62                   2332.446442               7.068020   \n",
       "                    77                   3888.129890               8.348105   \n",
       "                    136                  1433.261490               2.831134   \n",
       "                    172                  2136.363373               6.192358   \n",
       "...                                              ...                    ...   \n",
       "2022-05-16-3 005    7636                  207.059798               2.045035   \n",
       "                    7642                  760.313816               2.559979   \n",
       "                    7655                  282.575855               2.354799   \n",
       "                    7667                  664.830420               2.607178   \n",
       "                    7669                  846.549351               2.411822   \n",
       "\n",
       "                            spike_slope_amp_lower   spike_area2  \\\n",
       "piece_id     run_id unit_id                                       \n",
       "2017-08-14-1 000    18                   9.254678   9250.087891   \n",
       "                    62                   7.774821   9786.713867   \n",
       "                    77                   9.799949  10104.735352   \n",
       "                    136                  3.057625   4007.094238   \n",
       "                    172                  7.121211   6984.326660   \n",
       "...                                           ...           ...   \n",
       "2022-05-16-3 005    7636                 3.408392    264.043884   \n",
       "                    7642                 3.128863   1726.214355   \n",
       "                    7655                 3.767678    262.880310   \n",
       "                    7667                 3.067268   1524.838501   \n",
       "                    7669                 3.483742   2415.016113   \n",
       "\n",
       "                            spike_width_half_max_amp   axon_vel  \\\n",
       "piece_id     run_id unit_id                                       \n",
       "2017-08-14-1 000    18                         120.0   0.000000   \n",
       "                    62                          94.0   0.000000   \n",
       "                    77                         106.0   0.000000   \n",
       "                    136                        106.0   0.000000   \n",
       "                    172                         95.0   0.000000   \n",
       "...                                              ...        ...   \n",
       "2022-05-16-3 005    7636                        17.0  83.067218   \n",
       "                    7642                        85.0  77.471309   \n",
       "                    7655                        15.0  73.196644   \n",
       "                    7667                        99.0  77.168354   \n",
       "                    7669                        84.0   0.000000   \n",
       "\n",
       "                            label_manual_input              cell_id  \\\n",
       "piece_id     run_id unit_id                                           \n",
       "2017-08-14-1 000    18                    45.0    (2017-08-14-1, 0)   \n",
       "                    62                    25.0    (2017-08-14-1, 1)   \n",
       "                    77                    45.0    (2017-08-14-1, 2)   \n",
       "                    136                   45.0    (2017-08-14-1, 3)   \n",
       "                    172                   25.0    (2017-08-14-1, 4)   \n",
       "...                                        ...                  ...   \n",
       "2022-05-16-3 005    7636                  46.0  (2022-05-16-3, 481)   \n",
       "                    7642                  25.0  (2022-05-16-3, 482)   \n",
       "                    7655                  57.0  (2022-05-16-3, 483)   \n",
       "                    7667                  46.0  (2022-05-16-3, 484)   \n",
       "                    7669                  25.0  (2022-05-16-3, 485)   \n",
       "\n",
       "                            label_manual_text  label_manual  \n",
       "piece_id     run_id unit_id                                  \n",
       "2017-08-14-1 000    18              ON midget          45.0  \n",
       "                    62            OFF parasol          25.0  \n",
       "                    77              ON midget          45.0  \n",
       "                    136             ON midget          45.0  \n",
       "                    172           OFF parasol          25.0  \n",
       "...                                       ...           ...  \n",
       "2022-05-16-3 005    7636           ON parasol          46.0  \n",
       "                    7642          OFF parasol          25.0  \n",
       "                    7655                 crap          57.0  \n",
       "                    7667           ON parasol          46.0  \n",
       "                    7669          OFF parasol          25.0  \n",
       "\n",
       "[4471 rows x 45 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop Large Columns and Columns not Critical to Deep Learning Features\n",
    "# if the ct is very large we'll drop the big columns like STA and EI to save disk space, as they can be\n",
    "# easily reloaded later as needed\n",
    "drop_big_columns = ct.unit_table.shape[0] > 10000\n",
    "# Removed 'ei' from big_columns_per_dataset b/c will likely use\n",
    "big_columns_per_dataset = ['ei','alex_id','spike_times','spike_count','spike_waveform_maxenergy','spike_waveform_smart','ei_edge','ei_peak','ei_axon_only','ei_energy_raw','map_ei_energy','map_ei_energy_early','map_ei_energy_late']\n",
    "\n",
    "# now generate the features we listed above, and display the resulting units_table\n",
    "# check out all of those new columns, which you can use to make your analysis\n",
    "ct.generate_features('all', features_to_generate_by_dataset, features_to_generate_overall,\n",
    "                     force_features=False,\n",
    "                     load_analysis_data=True,\n",
    "                     ignore_errors=False,\n",
    "                     drop_big_columns=True,\n",
    "                     big_columns_per_dataset=big_columns_per_dataset)\n",
    "display(ct.unit_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9de453a-3d88-4b60-9213-b784d30b397f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~ Saving 7 pieces, to /Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/\n",
      "~ Saving entire datasets table for later per-piece file loading\n",
      "~ glady saved the whole dataset_table to /Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/ctds_test45to52.pkl\n",
      "*** timer  started\n",
      "~ piece_id 2017-08-14-1 with 1 runs, 380 cells, 380 units\n",
      "~ Saved datasets, cells, units to pandas DataFrames at\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/ctd_2017-08-14-1_[d,c,u].pkl\n",
      "*** elapsed 0s of 0s = 0.0m elapsed, of 0.0m estimated (1/7) (26.7 / sec)\n",
      "~ piece_id 2017-10-30-7 with 1 runs, 576 cells, 576 units\n",
      "~ Saved datasets, cells, units to pandas DataFrames at\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/ctd_2017-10-30-7_[d,c,u].pkl\n",
      "*** elapsed 0s of 0s = 0.0m elapsed, of 0.0m estimated (2/7) (23.4 / sec)\n",
      "~ piece_id 2018-02-06-4 with 1 runs, 603 cells, 603 units\n",
      "~ Saved datasets, cells, units to pandas DataFrames at\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/ctd_2018-02-06-4_[d,c,u].pkl\n",
      "*** elapsed 0s of 0s = 0.0m elapsed, of 0.0m estimated (3/7) (22.2 / sec)\n",
      "~ piece_id 2018-03-01-0 with 1 runs, 1160 cells, 1160 units\n",
      "~ Saved datasets, cells, units to pandas DataFrames at\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/ctd_2018-03-01-0_[d,c,u].pkl\n",
      "*** elapsed 0s of 0s = 0.0m elapsed, of 0.0m estimated (4/7) (18.5 / sec)\n",
      "~ piece_id 2018-11-12-5 with 1 runs, 576 cells, 576 units\n",
      "~ Saved datasets, cells, units to pandas DataFrames at\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/ctd_2018-11-12-5_[d,c,u].pkl\n",
      "*** elapsed 0s of 0s = 0.0m elapsed, of 0.0m estimated (5/7) (18.9 / sec)\n",
      "~ piece_id 2019-11-07-0 with 1 runs, 690 cells, 690 units\n",
      "~ Saved datasets, cells, units to pandas DataFrames at\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/ctd_2019-11-07-0_[d,c,u].pkl\n",
      "*** elapsed 0s of 0s = 0.0m elapsed, of 0.0m estimated (6/7) (19.0 / sec)\n",
      "~ piece_id 2022-05-16-3 with 1 runs, 486 cells, 486 units\n",
      "~ Saved datasets, cells, units to pandas DataFrames at\n",
      "/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/ctd_2022-05-16-3_[d,c,u].pkl\n",
      "*** elapsed 0s of 0s = 0.0m elapsed, of 0.0m estimated (7/7) (19.5 / sec)\n",
      "~ Done saving, go in peace.\n"
     ]
    }
   ],
   "source": [
    "# this function will save the units, cells, and dataset_table row in its own table\n",
    "# the save_name argument is specific to you and this project, always, and saves your dataset_table in a\n",
    "# single file so you can easily reload the whole set of datasets\n",
    "\n",
    "save_name = 'test45to52'  \n",
    "scratch_file_root = '/Volumes/Scratch/Users/mads/celltable_datasets/featExtractDL/test/' # replace my name!\n",
    "\n",
    "save_file = 1\n",
    "\n",
    "if save_file:\n",
    "    ct.file_save_pieces(save_name=save_name, file_root=scratch_file_root)\n",
    "else:\n",
    "    print('NO SAVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1861a380-6bef-4bbe-93ee-b566c64d2cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d946242-fb62-4de6-871d-466dd89c14e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
